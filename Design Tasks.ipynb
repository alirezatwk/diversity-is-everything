{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fmxTbpiBG2w3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import gym\n",
        "from math import sqrt\n",
        "from scipy.stats import t\n",
        "from statistics import mean\n",
        "from tqdm import tqdm\n",
        "from abc import ABC, abstractmethod\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "#from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pickle\n",
        "import plotly.express as px\n",
        "\n",
        "from abc import ABC, abstractmethod\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from utils.agent_creator import AgentCreator\n",
        "from utility_functions import ProspectUtilityFunction\n",
        "from environments.multi_armed_bandit import MultiArmedBanditEnvironment\n",
        "from rewards import MultinomialReward\n",
        "from agents import EpsilonGreedyAgent, SocialAgent\n",
        "from results import ActionsResult\n",
        "from visualizers.probability_of_choosing_best_action import ProbabilityOfChoosingBestActionVisualizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXGaCzywZb8N",
        "outputId": "2a02e1f8-d899-43f9-af3e-85a8d028fa9a"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "73ZyrJoSEr0j"
      },
      "source": [
        "# Implementations"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "DDAUQ9OOE00W"
      },
      "source": [
        "## Rewards"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JcicFR7yDweH"
      },
      "outputs": [],
      "source": [
        "class MultinomialReward():\n",
        "    def __init__(self, rewards, probs):\n",
        "        \"\"\"\n",
        "        rewards: a list of rewards are given by an specific arm\n",
        "        probs: a list of probabilities correspondant to each reward in rewards list\n",
        "        \"\"\"\n",
        "        self.rewards = rewards\n",
        "        self.probs = probs\n",
        "        self.mean = np.array(probs) @ np.array(rewards)        \n",
        "\n",
        "    def get_reward(self, t):\n",
        "        return random.choices(self.rewards, weights = self.probs, k = 1)[0]\n",
        "\n",
        "    def exp_u(self, agent):\n",
        "        u = [agent.utility_function(r) for r in self.rewards]\n",
        "        exp_u = np.array(self.probs) @ np.array(u)  \n",
        "        return exp_u"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ou6K5LJuDweI"
      },
      "outputs": [],
      "source": [
        "class DeteriministicReward():\n",
        "    def __init__(self, reward):\n",
        "        \"\"\"\n",
        "        rewards: a list of rewards are given by a specific arm\n",
        "        \"\"\"\n",
        "        self.reward = reward\n",
        "        self.mean = reward\n",
        "        \n",
        "    def get_reward(self, t):\n",
        "        return self.reward\n",
        "    \n",
        "    def exp_u(self, agent):\n",
        "        u = agent.utility_function(self.mean) \n",
        "        exp_u = u\n",
        "        return exp_u"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "nwIgeTb0DweJ"
      },
      "outputs": [],
      "source": [
        "class GaussianReward():\n",
        "    def __init__(self, mean, std):\n",
        "        \"\"\"\n",
        "        mean: a float shows the mean of gaussian distribution related to reward are given by a specific arm \n",
        "        std: a float shows the standard deviation of gaussian distribution related to reward are given by a specific arm\n",
        "        \"\"\"\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def get_reward(self, t):\n",
        "        return np.random.normal(loc=self.mean, scale=self.std)\n",
        "    \n",
        "    def exp_u(self, agent, n_samples = 1000):\n",
        "        utility_distribution = [agent.utility_function(np.random.normal(loc=self.mean, scale=self.std)) for i in range(n_samples)]\n",
        "        return mean(utility_distribution)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "eliQKoxtDweJ"
      },
      "outputs": [],
      "source": [
        "class Students_t_distReward():\n",
        "    def __init__(self,dof, mean, std):\n",
        "        \"\"\"\n",
        "        dof: an integer shows degree of freedom for t-distribution\n",
        "        mean: a float shows the mean of gaussian distribution related to reward are given by a specific arm \n",
        "        std: a float shows the standard deviation of gaussian distribution related to reward are given by a specific arm\n",
        "        \"\"\"\n",
        "        self.dof = dof\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def get_reward(self, t):\n",
        "        return t.rvs(df = self.dof, loc=self.mean, scale=self.std)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OqY-W0PZMG1d"
      },
      "outputs": [],
      "source": [
        "class MultinomialReward_NonStationary():\n",
        "    def __init__(self, rewards, probs, switch_t):\n",
        "        \"\"\"\n",
        "        rewards: a list of rewards are given by an specific arm\n",
        "        probs: a list of probabilities correspondant to each reward in rewards list\n",
        "        switch_t: an integer determine the swtich time\n",
        "        \"\"\"\n",
        "        self.rewards = rewards\n",
        "        self.probs = probs\n",
        "        self.mean = np.array(probs) @ np.array(rewards)  \n",
        "        self.switch_t = switch_t\n",
        "\n",
        "    def get_reward(self, t):\n",
        "        if t < self.switch_t:\n",
        "            return random.choices(self.rewards, weights = self.probs, k = 1)[0]\n",
        "        \n",
        "        else:\n",
        "            return random.choices(self.rewards[::-1], weights = self.probs, k = 1)[0]\n",
        "    \n",
        "    def exp_u(self, agent):\n",
        "        u = [agent.utility_function(r) for r in self.rewards]\n",
        "        exp_u = np.array(self.probs) @ np.array(u)  \n",
        "        return exp_u"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "11fHtdR3E5X_"
      },
      "source": [
        "## N-Armed Bandit Environments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "LHflIod8DweK"
      },
      "outputs": [],
      "source": [
        "class MutliArmedBanditEnvironment():\n",
        "    def __init__(self, rewards, episode_max_length, id = None, container=None):\n",
        "        \"\"\"\n",
        "        rewards: a list of reward object, length = number of arms\n",
        "        episode_max_length: maximum length of each episode \n",
        "        id: id of environment\n",
        "        container: \n",
        "        \"\"\"\n",
        "        state_space = gym.spaces.Discrete(1)\n",
        "        action_space = gym.spaces.Discrete(len(rewards))\n",
        "\n",
        "        self.action_space = action_space\n",
        "        self.observation_space = state_space\n",
        "        self.state = None\n",
        "        self.id = id\n",
        "        self.agents = {}\n",
        "        \n",
        "        if container != None:\n",
        "            container.register_environment(self)\n",
        "        self.arms_rewards = rewards # consits all rewards method\n",
        "        self.episode_max_length = episode_max_length\n",
        "        self.state = {\n",
        "            'length': 0,\n",
        "            'last_action': None\n",
        "        }\n",
        "\n",
        "    def add_agent(self, agent_id):\n",
        "        self.agents_last_choice[agent_id] = -1 \n",
        "        \n",
        "    def calculate_reward(self, action):\n",
        "        return self.arms_rewards[action].get_reward(self.state['length'])\n",
        "\n",
        "    def terminated(self):\n",
        "        return self.state['length'] >= self.episode_max_length\n",
        "\n",
        "    def observe(self):\n",
        "        return {}\n",
        "\n",
        "    def n_actions(self):\n",
        "        return self.action_space.n\n",
        "\n",
        "    def next_state(self, action):\n",
        "        self.state['length'] += 1\n",
        "        self.state['last_action'] = action\n",
        "    \n",
        "    def get_info(self):\n",
        "        return {} \n",
        "\n",
        "    def update_selected(self, action, agent_id):\n",
        "        if agent_id == -1:\n",
        "            return\n",
        "        self.agents_last_choice[agent_id] = action\n",
        "\n",
        "    def step(self, action, agent_id):\n",
        "        reward = self.calculate_reward(action)\n",
        "        observation = self.observe()\n",
        "        info = self.get_info()\n",
        "        self.next_state(action)\n",
        "        done = self.terminated()\n",
        "        self.update_selected(action, agent_id) #agent_id == -1 ==> do nothing\n",
        "        return observation, reward, done, info\n",
        "\n",
        "    def reset(self):\n",
        "        self.state['length'] = 0\n",
        "        self.state['last_action'] = None\n",
        "\n",
        "    def render(self, mode='human'):\n",
        "        print('{}:\\taction={}'.format(self.state['length'], self.state['last_action']))\n",
        "\n",
        "    def close(self):\n",
        "        return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "qAQ_lcEVUjfk"
      },
      "outputs": [],
      "source": [
        "class SocialMutliArmedBanditEnvironment():\n",
        "    def __init__(self, rewards, episode_max_length, id = None, container = None):\n",
        "        \"\"\"\n",
        "        rewards: a list of reward object, length = number of arms\n",
        "        episode_max_length: maximum length of each episode \n",
        "        id: id of environment\n",
        "        container: \n",
        "        \"\"\"\n",
        "        self.observation_space = gym.spaces.Discrete(1)\n",
        "        self.action_space = gym.spaces.Discrete(len(rewards))\n",
        "        \n",
        "        if container != None:\n",
        "            container.register_environment(self)\n",
        "\n",
        "        self.id = id\n",
        "        self.arms_rewards = rewards\n",
        "        self.agents_last_choice = {}\n",
        "        self.episode_max_length = episode_max_length\n",
        "        # self.optimal_action = np.argmax(R_mean)\n",
        "\n",
        "        self.state = {\n",
        "            'length': 0,\n",
        "            'last_action': None\n",
        "        }\n",
        "    \n",
        "    def add_agent(self, agent_id):\n",
        "        self.agents_last_choice[agent_id] = -1 \n",
        "     \n",
        "    def calculate_reward(self, action):\n",
        "        return self.arms_rewards[action].get_reward(self.state['length'])\n",
        "    \n",
        "    def update_selected(self, actions, agents_id):\n",
        "        if len(actions) != len(agents_id):\n",
        "            raise(\"WTF?\")\n",
        "        for i in range(len(actions)):\n",
        "            self.agents_last_choice[agents_id[i]] = actions[i]\n",
        "        \n",
        "    \n",
        "    def terminated(self):\n",
        "        return self.state['length'] >= self.episode_max_length\n",
        "\n",
        "    def observe(self):\n",
        "        return {}\n",
        "    \n",
        "    def n_actions(self):\n",
        "        return self.action_space.n\n",
        "\n",
        "    def next_state(self, action):\n",
        "        self.state['length'] += 1\n",
        "        self.state['last_action'] = action\n",
        "    \n",
        "    def get_info(self):\n",
        "        return {} \n",
        "\n",
        "    def step(self, action, agent_id):\n",
        "        reward = self.calculate_reward(action)\n",
        "        observation = self.observe()\n",
        "        info = self.get_info()\n",
        "        self.next_state(action)\n",
        "        done = self.terminated()\n",
        "        # self.update_selected(action, agent_id) #agent_id == -1 ==> do nothing\n",
        "        return observation, reward, done, info\n",
        "    \n",
        "    def config(self):\n",
        "        self.agents_last_choice = []\n",
        "    \n",
        "    def reset(self):\n",
        "        self.state['length'] = 0\n",
        "        self.state['last_action'] = None\n",
        "        for key in list( self.agents_last_choice.keys()):\n",
        "            self.agents_last_choice[key] = -1\n",
        "    \n",
        "    def render(self, mode='human'):\n",
        "        print('{}:\\taction={}'.format(self.state['length'], self.state['last_action']))\n",
        "\n",
        "    def close(self):\n",
        "        return"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7vTZafAEE-8H"
      },
      "source": [
        "## Agents "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5JLeNiNNDweL"
      },
      "outputs": [],
      "source": [
        "class AgentBase:\n",
        "    def __init__(self, lr, environment = None, alpha = 1,beta = 1,gamma = 1,\n",
        "                 lr_decay = 1):\n",
        "        \"\"\"\n",
        "        environment: the env object that agent interact with it\n",
        "        id: an int, the number of agent, used as a key in agents dict in environment\n",
        "        alpha, beta, gamma: float numbers are used for measuring utility based on prospect theory\n",
        "        lr = a float number, determine the rate of learning\n",
        "        lr_decay = a float number, determine the decay of learning rate \n",
        "        \"\"\"\n",
        "        self.environment = environment\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta \n",
        "        self.gamma = gamma\n",
        "        self.lr = lr\n",
        "        self.lr_decay = lr_decay\n",
        "\n",
        "    def set_environment(self, env):\n",
        "        self.environment = env\n",
        "\n",
        "    def set_id(self, id):\n",
        "        self.id = id \n",
        "\n",
        "    @abstractmethod\n",
        "    def take_action(self) -> (object, float, bool, object):\n",
        "        # in this method, you MUST call the `step` method of \n",
        "        # the environment and observe the results and return them like:\n",
        "        # return observation, reward, done, info\n",
        "        pass\n",
        "    \n",
        "    def utility_function(self,reward):\n",
        "        if reward >= 0 :\n",
        "            u = reward ** self.alpha\n",
        "        else:\n",
        "            u =  -1 * self.gamma * ((-reward)** self.beta)\n",
        "        return u "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "syUMOjD4LRpi"
      },
      "source": [
        "### Learner Agents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "7HYwd6-7DweL"
      },
      "outputs": [],
      "source": [
        "class EpsilonGreedyAgent(AgentBase): \n",
        "    def __init__(self, environment = None, alpha = 1, beta = 1, gamma = 1, lr = None,\n",
        "                 lr_decay = 1, epsilon = 0.1, epsilon_decay = 1,  optimistic = False):\n",
        "        \"\"\"\n",
        "        environment: the env object that agent interact with it\n",
        "        id: String or float or int, the name or the number of agent, used as a key in agents dict in environment\n",
        "        alpha, beta, gamma: float numbers are used for measuring utility based on prospect theory\n",
        "        lr = a float number, determine the rate of learning\n",
        "        lr_decay = a float number, determine the decay of learning rate \n",
        "        epsilon = a float number, determine degree of exploration\n",
        "        epsilon_decay = a float number, determine degree of decaying epsilon\n",
        "        optimistic = a bool, determine using optimistic initialization\n",
        "        \"\"\"\n",
        "        #Add Temperature\n",
        "        super(EpsilonGreedyAgent, self).__init__(lr, environment, alpha, beta, gamma,  lr_decay)\n",
        "        self.epsilon = epsilon\n",
        "        self.epsilon_decay = epsilon_decay\n",
        "        if environment is not None:\n",
        "            self.n_actions = self.environment.n_actions()\n",
        "            \n",
        "            self.Q = np.zeros((self.n_actions))     #action value fuction\n",
        "            # self.Q = np.random.normal(size=(self.n_actions,1))\n",
        "            self.N = np.zeros((self.n_actions))     #number of doing an action \n",
        "\n",
        "    def get_number_actions(self):\n",
        "        return self.N\n",
        "    \n",
        "    def set_environment(self, env):\n",
        "        self.environment = env\n",
        "        self.n_actions = self.environment.n_actions()\n",
        "\n",
        "        self.Q = np.zeros((self.n_actions))     #action value fuction\n",
        "        # self.Q = np.random.normal(size=(self.n_actions,1))\n",
        "        self.N = np.zeros((self.n_actions))     #number of doing an action \n",
        "\n",
        "    def update(self, action, utility):\n",
        "        self.epsilon = self.epsilon * self.epsilon_decay\n",
        "        self.N[action] += 1\n",
        "        if self.lr is not None:\n",
        "            self.Q[action] += (utility - self.Q[action]) * self.lr\n",
        "            self.lr = self.lr * self.lr_decay \n",
        "        else:\n",
        "            self.Q[action] += (utility - self.Q[action])/self.N[action] \n",
        "\n",
        "    def select_action(self):\n",
        "        rand = np.random.random()\n",
        "        if rand < self.epsilon:\n",
        "            action = np.random.randint(self.n_actions)\n",
        "        else:\n",
        "            action = np.random.choice(np.flatnonzero(self.Q == self.Q.max()))\n",
        "            # max_indices = np.argwhere(self.Q == np.amax(self.Q)).flatten()\n",
        "            # action = int(np.random.choice(max_indices))\n",
        "            # action = np.argmax(self.Q)\n",
        "        return action\n",
        "\n",
        "    def take_action(self) -> (object, float, bool, object):\n",
        "        if self.environment is None:\n",
        "            raise(\"Env is not defined\",)\n",
        "        action = self.select_action()\n",
        "        obs, r, d, i = self.environment.step(action, self.id)\n",
        "        u = self.utility_function(r)\n",
        "        self.update(action,u)\n",
        "        \n",
        "        return r, action , u\n",
        "\n",
        "    def get_Q(self):\n",
        "        return self.Q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "VZYTv8J3VAMO"
      },
      "outputs": [],
      "source": [
        "class UCBAgent(AgentBase):\n",
        "    def __init__(self, c, environment = None, alpha = 1, beta = 1, gamma = 1,\n",
        "                 lr = None, lr_decay = 1,):\n",
        "        \"\"\"\n",
        "        c: a float, determine the degree of exploration \n",
        "        environment: the env object that agent interact with it\n",
        "        id: String or float or int, the name or the number of agent, used as a key in agents dict in environment\n",
        "        alpha, beta, gamma: float numbers are used for measuring utility based on prospect theory\n",
        "        lr = a float number, determine the rate of learning\n",
        "        lr_decay = a float number, determine the decay of learning rate \n",
        "        \"\"\"\n",
        "        super(UCBAgent, self).__init__( lr, environment, alpha, beta, gamma, lr_decay)\n",
        "        self.c = c\n",
        "        self.trial = 0                                          #number of total trials \n",
        "\n",
        "        if environment is not None:\n",
        "            self.n_actions = self.environment.n_actions()\n",
        "            self.Q = np.zeros((self.n_actions))                 #action value function(expected reward) for each arm\n",
        "            self.N = np.zeros((self.n_actions))                 #number of doing each arm\n",
        "            self.UCB = np.zeros((self.n_actions))      #Upper confidence bound for each arm\n",
        "            \n",
        "    def select_action(self): \n",
        "        # An action not chosen so far is the maximizer by default\n",
        "        zero_idx = np.where(self.N == 0)[0]\n",
        "        if len(zero_idx) > 0:\n",
        "            return zero_idx[0]       \n",
        "            \n",
        "        self.UCB = self.Q + np.sqrt(self.c * np.log(self.trial+1)/(self.N))\n",
        "        action = np.random.choice(np.flatnonzero(self.UCB == self.UCB.max()))\n",
        "        return action \n",
        "\n",
        "    def set_environment(self, env):\n",
        "        self.environment = env\n",
        "        self.n_actions = self.environment.n_actions()\n",
        "        self.Q = np.zeros((self.n_actions))                 #action value function(expected reward) for each arm\n",
        "        self.N = np.zeros((self.n_actions))                 #number of doing each arm\n",
        "        self.UCB = np.zeros((self.n_actions))      #Upper confidence bound for each arm\n",
        "\n",
        "    def update(self, action, u):        \n",
        "        # update action values\n",
        "        self.trial += 1\n",
        "        self.N[action] = self.N[action] + 1\n",
        "        if self.lr is not None:\n",
        "            self.Q[action] += self.lr*(u-self.Q[action])\n",
        "            self.lr = self.lr * self.lr_decay\n",
        "        else:\n",
        "            self.Q[action] += (u-self.Q[action]) / self.N[action]\n",
        "\n",
        "        \n",
        "    def take_action(self) -> (object, float, bool, object):\n",
        "        if self.environment is None:\n",
        "            raise(\"Environment is not defined\")\n",
        "        action = self.select_action()\n",
        "        obs, r, d, i = self.environment.step(action, self.id)\n",
        "        u = self.utility_function(r)\n",
        "        self.update(action, u)\n",
        "        return r, action, u"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "38CnYMSoByxk"
      },
      "outputs": [],
      "source": [
        "class GradientBanditAgent(AgentBase): \n",
        "    def __init__(self, environment = None, alpha = 1, beta = 1, gamma = 1,\n",
        "                 lr = 0.1, lr_decay = 1, optimistic = False, Baseline_lr = None):\n",
        "        \"\"\"\n",
        "        environment: the env object that agent interact with it\n",
        "        id: String or float or int, the name or the number of agent, used as a key in agents dict in environment\n",
        "        alpha, beta, gamma: float numbers are used for measuring utility based on prospect theory\n",
        "        lr = a float number, determine the rate of learning\n",
        "        lr_decay = a float number, determine the decay of learning rate \n",
        "        optimistic = a bool, determine using optimistic initialization\n",
        "        baseline_lr: a float number, determine the rate of updating the baseline\n",
        "        \"\"\"\n",
        "        super(GradientBanditAgent, self).__init__(lr, environment, alpha, beta, gamma, lr_decay)\n",
        "\n",
        "        self.R_lr = Baseline_lr\n",
        "        self.avg_rew = 0   \n",
        "        self.N = 0      \n",
        "        if environment is not None:\n",
        "            self.n_actions = self.environment.n_actions()\n",
        "            self.H = np.zeros((self.n_actions))\n",
        "            self.P = (1/self.n_actions)*np.ones((self.n_actions))\n",
        "    \n",
        "    def set_environment(self, env):\n",
        "        self.environment = env\n",
        "        self.n_actions = self.environment.n_actions()\n",
        "        self.H = np.zeros((self.n_actions))\n",
        "        self.P = (1/self.n_actions)*np.ones((self.n_actions))       \n",
        "\n",
        "    def update(self, action, utility):\n",
        "        self.lr = self.lr * self.lr_decay\n",
        "        self.N += 1\n",
        "        if self.R_lr is not None:\n",
        "            self.avg_rew += (utility - self.avg_rew) * self.R_lr\n",
        "        else:\n",
        "            self.avg_rew += (utility - self.avg_rew)/self.N\n",
        "\n",
        "        for i in range(len(self.H)):\n",
        "            if i == action :\n",
        "                self.H[i] += self.lr *(utility - self.avg_rew)*(1-self.P[i])\n",
        "\n",
        "            else:\n",
        "                self.H[i] -=  self.lr *(utility - self.avg_rew)*(self.P[i])\n",
        "\n",
        "        for i in range(len(self.P)):\n",
        "            self.P[i] = np.exp(self.H[i]) / np.sum(np.exp(self.H))\n",
        "\n",
        "    def get_all(self):\n",
        "        return self.H,self.P\n",
        "\n",
        "    def select_action(self):\n",
        "        action = int(np.random.choice(list(range(self.n_actions)), size=1,p=self.P))       \n",
        "        return action \n",
        "\n",
        "    def take_action(self) -> (object, float, bool, object):\n",
        "        if self.environment is None:\n",
        "            raise(\"Env is not defined\",)\n",
        "        action = self.select_action()\n",
        "        obs, r, d, i = self.environment.step(action, self.id)\n",
        "        #(obs, r, d, i)\n",
        "        u = self.utility_function(r)\n",
        "        self.update(action,u)\n",
        "        #self.environment.render()\n",
        "        return r, action , u\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "1HNl0mID_YrT"
      },
      "outputs": [],
      "source": [
        "class ActorCriticAgent(AgentBase): \n",
        "    def __init__(self, environment = None, alpha = 1, beta = 1, gamma = 1,\n",
        "                 lr = 0.1, lr_decay = 1, optimistic = False):\n",
        "        \"\"\"\n",
        "        environment: the env object that agent interact with it\n",
        "        id: String or float or int, the name or the number of agent, used as a key in agents dict in environment\n",
        "        alpha, beta, gamma: float numbers are used for measuring utility based on prospect theory\n",
        "        lr = a float number, determine the rate of learning\n",
        "        lr_decay = a float number, determine the decay of learning rate \n",
        "        optimistic = a bool, determine using optimistic initialization\n",
        "        \"\"\"\n",
        "        super(ActorCriticAgent, self).__init__(lr, environment, alpha, beta, gamma, lr_decay)\n",
        "        self.N = 0      \n",
        "        if environment is not None:\n",
        "            self.n_actions = self.environment.n_actions()\n",
        "            self.Q = np.zeros((self.n_actions))     #action value fuction\n",
        "            self.H = np.zeros((self.n_actions))\n",
        "            self.P = (1/self.n_actions)*np.ones((self.n_actions))\n",
        "    \n",
        "    def set_environment(self, env):\n",
        "        self.environment = env\n",
        "        self.n_actions = self.environment.n_actions()\n",
        "        self.Q = np.zeros((self.n_actions))     #action value fuction\n",
        "        self.H = np.zeros((self.n_actions))\n",
        "        self.P = (1/self.n_actions)*np.ones((self.n_actions))        \n",
        "\n",
        "    def update(self,action,utility):\n",
        "        self.lr = self.lr * self.lr_decay\n",
        "        self.N += 1\n",
        "        if self.lr is not None:\n",
        "            self.Q[action] += (utility - self.Q[action]) * self.lr\n",
        "            self.lr = self.lr * self.lr_decay \n",
        "        else:\n",
        "            self.Q[action] += (utility - self.Q[action])/self.N[action] \n",
        "\n",
        "        for i in range(len(self.H)):\n",
        "            if i == action :\n",
        "                self.H[i] += self.lr *(utility - self.Q[i])*(1-self.P[i])\n",
        "\n",
        "            else:\n",
        "                self.H[i] -=  self.lr *(utility - self.Q[i])*(self.P[i])\n",
        "\n",
        "        for i in range(len(self.P)):\n",
        "            self.P[i] = np.exp(self.H[i]) / np.sum(np.exp(self.H))\n",
        "\n",
        "    def get_all(self):\n",
        "        return self.H,self.P\n",
        "\n",
        "    def select_action(self):\n",
        "        action = int(np.random.choice(list(range(self.n_actions)), size=1,p=self.P))  \n",
        "        return action\n",
        "\n",
        "    def take_action(self) -> (object, float, bool, object):\n",
        "        if self.environment is None:\n",
        "            raise(\"environment is not defined\")\n",
        "        action = self.select_action()\n",
        "        obs, r, d, i = self.environment.step(action, self.id)\n",
        "        #print(obs, r, d, i)\n",
        "        u = self.utility_function(r)\n",
        "        self.update(action,u)\n",
        "        #self.environment.render()\n",
        "        return r, action , u"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ej-BOALdDr4Y"
      },
      "outputs": [],
      "source": [
        "class ThompsonSamplingAgent(AgentBase):\n",
        "    def __init__(self, environment = None, alpha = 1, beta = 1, gamma = 1,\n",
        "                 lr = 0.1, lr_decay = 1):\n",
        "        \"\"\"\n",
        "        environment: the env object that agent interact with it\n",
        "        id: String or float or int, the name or the number of agent, used as a key in agents dict in environment\n",
        "        alpha, beta, gamma: float numbers are used for measuring utility based on prospect theory\n",
        "        lr = a float number, determine the rate of learning\n",
        "        lr_decay = a float number, determine the decay of learning rate \n",
        "        \"\"\"\n",
        "        super(ThompsonSamplingAgent, self).__init__(lr, environment, alpha, beta, gamma, lr_decay)\n",
        "        \n",
        "        if self.environment is not None:\n",
        "            self.n_actions = self.environment.n_actions()\n",
        "            self.stds = list(1000000000 * np.ones((self.n_actions,1)))  #stds of estimated gaussian distributions\n",
        "            self.means = list( np.zeros((self.n_actions,1)))            #means of estimated gaussian distributions\n",
        "\n",
        "    def set_environment(self, env):\n",
        "        self.environment = env \n",
        "        self.n_actions = self.environment.n_actions()\n",
        "        self.stds = list(1000000000 * np.ones((self.n_actions,1)))  #stds of estimated gaussian distributions\n",
        "        self.means = list( np.zeros((self.n_actions,1)))            #means of estimated gaussian distributions\n",
        "\n",
        "    def get_samples(self,means,stds):\n",
        "        samples = [np.random.normal(means[i],stds[i]) for i in range(len(means))]\n",
        "        return samples\n",
        "\n",
        "    def update(self, action, reward):\n",
        "        new_std = sqrt( 1 / ((1/self.stds[action]**2) + 1) )\n",
        "        new_mean = (reward + (self.means[action] / self.stds[action] ** 2)) / ((1/self.stds[action]**2) + 1) \n",
        "        self.means[action] = new_mean\n",
        "        self.stds[action] = new_std\n",
        "        return \n",
        "\n",
        "    def select_action(self):\n",
        "        samples = self.get_samples(self.means,self.stds)\n",
        "        action = np.argmax(samples)\n",
        "        return action \n",
        "\n",
        "    def take_action(self):# -> (object, float, bool, object):\n",
        "        if self.environment is None:\n",
        "            raise(\"Env is not defined\",)\n",
        "        action = self.select_action()\n",
        "        obs, r, d, i = self.environment.step(action, self.id)\n",
        "        u = self.utility_function(r)\n",
        "        self.update(action, u)\n",
        "        #print(obs, r, d, i)\n",
        "        #self.environment.render()\n",
        "        return r,action, u"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zTOmpSzeEpZG"
      },
      "source": [
        "### Coded Agents:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "C-ATGsJvaT3z"
      },
      "outputs": [],
      "source": [
        "class AlwaysBestAgent(AgentBase):\n",
        "    def __init__(self, environment = None, alpha = 1, beta = 1, gamma = 1, lr = None):\n",
        "        \"\"\"\n",
        "        environment: the env object that agent interact with it\n",
        "        id: String or float or int, the name or the number of agent, used as a key in agents dict in environment\n",
        "        alpha, beta, gamma: float numbers are used for measuring utility based on prospect theory\n",
        "        \"\"\"\n",
        "        super(AlwaysBestAgent, self).__init__(lr, environment, alpha, beta, gamma)\n",
        "        if self.environment is not None:\n",
        "            self.EU = np.array([self.utility_function(r.mean) for r in self.environment.arms_rewards])\n",
        "            self.bestaction = np.random.choice(np.flatnonzero(self.EU == self.EU.max()))\n",
        "        # self.regret = []\n",
        "    \n",
        "    def set_environment(self, env):\n",
        "        self.environment = env \n",
        "        self.EU = np.array([self.utility_function(r.mean) for r in self.environment.arms_rewards])\n",
        "        self.bestaction = np.random.choice(np.flatnonzero(self.EU == self.EU.max())) \n",
        "           \n",
        "    def take_action(self):\n",
        "        if self.environment is None:\n",
        "            raise(\"environment is not defined\")\n",
        "        obs, r, d, i = self.environment.step(self.bestaction, self.id)\n",
        "        #self.r = self.r + self.environment.rewards[np.argmax([r.m for r in self.environment.rewards])].m - self.environment.rewards[indx].mean\n",
        "        #self.regret.append(self.r)\n",
        "        return r, self.bestaction, self.utility_function(r)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "MrQKW3UQaV4r"
      },
      "outputs": [],
      "source": [
        "class PercentBestAgent(AgentBase):\n",
        "    def __init__(self, p, environment = None, alpha = 1, beta = 1, gamma = 1, \n",
        "                 increase = 0, limit = 1, zero_at = False, lr = None):\n",
        "        \"\"\"\n",
        "        p: a float number between 0 and 1, determine the proportion of selecting the optimal arm\n",
        "        environment: the env object that agent interact with it\n",
        "        id: String or float or int, the name or the number of agent, used as a key in agents dict in environment\n",
        "        alpha, beta, gamma: float numbers are used for measuring utility based on prospect theory\n",
        "        increase: a float number between 0 and 1, determine the amount of selecting the optimal arm\n",
        "        limit: a float number between 0 and 1, determine the upper bound of selecting the optimal arm\n",
        "        zero_at: a bool, determine that we revert the selecting probability to zero after reaching to one \n",
        "        \"\"\"\n",
        "        super(PercentBestAgent, self).__init__(lr, environment, alpha, beta, gamma)\n",
        "        self.p = p\n",
        "        self.increase = increase\n",
        "        self.zero_at = zero_at\n",
        "        self.limit = limit\n",
        "        if self.environment is not None:\n",
        "            self.EU = np.array([self.utility_function(r.mean) for r in self.environment.arms_rewards])\n",
        "            self.bestaction = np.random.choice(np.flatnonzero(self.EU == self.EU.max()))\n",
        "            self.n_actions = self.environment.n_actions()\n",
        "            # self.regret = []\n",
        "    \n",
        "    def set_environment(self, env):\n",
        "        self.environment = env\n",
        "        self.EU = np.array([self.utility_function(r.mean) for r in self.environment.arms_rewards])\n",
        "        self.bestaction = np.random.choice(np.flatnonzero(self.EU == self.EU.max()))\n",
        "        self.n_actions = self.environment.n_actions() \n",
        "\n",
        "    def take_action(self):\n",
        "        if self.environment is None:\n",
        "            raise(\"environment is not defined\")\n",
        "        \n",
        "        if np.random.rand() < self.p:\n",
        "            action = self.bestaction\n",
        "        else:\n",
        "            action = np.random.choice(self.n_actions)\n",
        "        \n",
        "        obs, r, d, i = self.environment.step(action, self.id)\n",
        "\n",
        "        #self.r = self.r + self.environment.rewards[np.argmax([r.m for r in self.environment.rewards])].m - self.environment.rewards[indx].m\n",
        "        #self.regret.append(self.r)\n",
        "\n",
        "        self.p = self.p + self.increase\n",
        "        if self.p > self.limit:\n",
        "            self.p = self.limit\n",
        "            self.increase = 0\n",
        "            \n",
        "        if self.zero_at:\n",
        "            if self.p > 1:\n",
        "                self.p = 0\n",
        "                self.increase = 0\n",
        "        return r, action, self.utility_function(r)\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "NUZk27PnaejZ"
      },
      "outputs": [],
      "source": [
        "class SecondBestAgent(AgentBase):\n",
        "    def __init__(self, environment = None, alpha = 1, beta = 1, gamma = 1, lr = None):\n",
        "        \"\"\"\n",
        "        environment: the env object that agent interact with it\n",
        "        id: String or float or int, the name or the number of agent, used as a key in agents dict in environment\n",
        "        alpha, beta, gamma: float numbers are used for measuring utility based on prospect theory\n",
        "        \"\"\"\n",
        "        super(SecondBestAgent, self).__init__(lr, environment, alpha, beta, gamma)\n",
        "        if self.environment is not None:\n",
        "            self.EU = np.array([self.utility_function(r.mean) for r in self.environment.arms_rewards])\n",
        "            SecondEU = np.array([x for x in self.EU if x < max(self.EU)])\n",
        "            self.secondbestaction = np.random.choice(np.flatnonzero(self.EU == SecondEU.max()))\n",
        "            # self.regret = []\n",
        "\n",
        "    def take_action(self):\n",
        "        obs, r, d, i = self.environment.step(self.secondbestaction, self.id)\n",
        "        return r, self.secondbestaction, self.utility_function(r)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "lkAuCmCBah9r"
      },
      "outputs": [],
      "source": [
        "class AlwaysWorstAgent(AgentBase):\n",
        "    def __init__(self, environment = None, alpha = 1, beta = 1, gamma = 1, lr = None):\n",
        "        \"\"\"\n",
        "        environment: the env object that agent interact with it\n",
        "        id: String or float or int, the name or the number of agent, used as a key in agents dict in environment\n",
        "        alpha, beta, gamma: float numbers are used for measuring utility based on prospect theory\n",
        "        \"\"\"\n",
        "        super(AlwaysWorstAgent, self).__init__(lr, environment, alpha, beta, gamma)\n",
        "        if self.environment is not None:\n",
        "            self.EU = np.array([self.utility_function(r.mean) for r in self.environment.arms_rewards])\n",
        "            self.worstaction = np.random.choice(np.flatnonzero(self.EU == self.EU.min()))\n",
        "        # self.regret = []\n",
        "\n",
        "    def set_environment(self, env):\n",
        "        self.environment = env    \n",
        "        self.EU = np.array([self.utility_function(r.mean) for r in self.environment.arms_rewards])\n",
        "        self.worstaction = np.random.choice(np.flatnonzero(self.EU == self.EU.min()))\n",
        "            \n",
        "    def take_action(self):\n",
        "        if self.environment is None:\n",
        "            raise(\"environment is not defined\")\n",
        "        obs, r, d, i = self.environment.step(self.worstaction, self.id)\n",
        "        return r, self.worstaction, self.utility_function(r)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "bp8MRB72EpZH"
      },
      "outputs": [],
      "source": [
        "class AlwaysRandomAgent(AgentBase):\n",
        "    def __init__(self, environment = None, alpha = 1, beta = 1, gamma = 1, lr = None):\n",
        "        \"\"\"\n",
        "        environment: the env object that agent interact with it\n",
        "        id: String or float or int, the name or the number of agent, used as a key in agents dict in environment\n",
        "        alpha, beta, gamma: float numbers are used for measuring utility based on prospect theory\n",
        "        \"\"\"\n",
        "        super(AlwaysRandomAgent, self).__init__(lr, environment, alpha, beta, gamma)\n",
        "        if self.environment is not None:\n",
        "            self.n_actions = self.environment.n_actions()\n",
        "            # self.regret = []\n",
        "\n",
        "    def set_environment(self, env):\n",
        "        self.environment = env \n",
        "        self.n_actions = self.environment.n_actions()\n",
        "\n",
        "    def take_action(self):\n",
        "        if self.environment is None:\n",
        "            raise(\"environment is not defined\")        \n",
        "        action = np.random.choice(self.n_actions)\n",
        "        obs, r, d, i = self.environment.step(action, self.id)\n",
        "        return r, action, self.utility_function(r)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "BDVpDK72u6-y"
      },
      "source": [
        "Agent id -1 is equivalant to None"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Social Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "YdKWVicoNAiy"
      },
      "outputs": [],
      "source": [
        "class LastActionSocialStrategy():\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        In this social strategy the learner copies the last action of the \n",
        "        selected agent in the society.\n",
        "        \"\"\"\n",
        "        self.n = 1\n",
        "        \n",
        "    def set_environment(self, env):\n",
        "        self.env = env\n",
        "        self.agents_id = list(env.agents_last_choice.keys())\n",
        "    \n",
        "    def select_action(self, social_information, agent_id):\n",
        "        # Choose the last action of agent from environment lookup table or your short-term memory  \n",
        "        return self.env.agents_last_choice[agent_id]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "vSq-xt6B6jDt"
      },
      "outputs": [],
      "source": [
        "class MostFrequentSocialStrategy():\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        In this social strategy the learner copies the most frequent action of \n",
        "        the selected agent in the society.\n",
        "        \"\"\"\n",
        "        self.n = 1\n",
        "    \n",
        "    def set_environment(self, env):\n",
        "        self.env = env\n",
        "        self.agents_id = list(env.agents_last_choice.keys())\n",
        "    \n",
        "    def select_action(self, social_information, agent_id):\n",
        "        # Choose the most frequent action of agent from your long-term memory      \n",
        "        return np.argmax(social_information[agent_id,:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "zKt85cNFsHS2"
      },
      "outputs": [],
      "source": [
        "class PreferenceBasedSocialAgent(AgentBase):\n",
        "\n",
        "    def __init__(self, ilm, lr = 0.1, env = None, alpha = 1,beta = 1,gamma = 1,):\n",
        "        \"\"\"\n",
        "        # TODO: Comment update other agents in same list(line 51)\n",
        "        # TODO: Change name of preference history to selecting policy history\n",
        "        ilm: an individual learner object\n",
        "        lr: an integer which set the learning rate\n",
        "        env: an environment object\n",
        "        \"\"\"\n",
        "        super(PreferenceBasedSocialAgent, self).__init__(lr, env, alpha = alpha, beta = beta, gamma = gamma)\n",
        "        self.ilm = ilm \n",
        "        self.t = 0 #trial\n",
        "        self.total_mean_reward = 0 \n",
        "        self.selecting_history = []\n",
        "        self.actions = []\n",
        "\n",
        "        if self.environment is not None:\n",
        "            self.n = len(self.environment.agents_last_choice) # number of agents\n",
        "            self.k = self.environment.n_actions() # number of actions\n",
        "            self.preferences = np.zeros(self.n)+0.0001\n",
        "            self.lrs = np.ones(self.n)*lr\n",
        "            self.social_information = np.zeros((self.n,self.k))\n",
        "            # uniform initialization, (Others can be done, ourself 1 the others zero)\n",
        "            self.selecting_policy = np.ones(self.n)/self.n\n",
        "            self.agents_id = list(env.agents_last_choice.keys())\n",
        "            self.id_2_ind = {self.agents_id[i]:i for i in range(self.n)}\n",
        "            self.preferences_history  = {i:[] for i in self.agents_id}\n",
        "\n",
        "    def set_environment(self, env):\n",
        "        self.environment = env \n",
        "        self.n = len(self.environment.agents_last_choice) # number of agents\n",
        "        self.k = self.environment.n_actions() # number of actions\n",
        "        self.preferences = np.zeros(self.n)+0.0001\n",
        "        self.lrs = np.ones(self.n)*self.lr\n",
        "        self.social_information = np.zeros((self.n,self.k))\n",
        "        # uniform initialization, (Others can be done, ourself 1 the others zero)\n",
        "        self.selecting_policy = np.ones(self.n)/self.n\n",
        "        self.agents_id = list(env.agents_last_choice.keys())\n",
        "        self.id_2_ind = {self.agents_id[i]:i for i in range(self.n)}\n",
        "        self.preferences_history  = {i:[] for i in self.agents_id}\n",
        "        self.ilm.set_environment(env)\n",
        "\n",
        "    def update(self, u, action, agent_id, ind_mode):\n",
        "        self.t += 1\n",
        "        self.total_mean_reward += (u - self.total_mean_reward)/self.t\n",
        "        same = []\n",
        "        for i in range(self.n):\n",
        "            # print(self.agents_id[i])\n",
        "            # print(i,self.environment.agents_last_choice[self.agents_id[i]])\n",
        "            self.social_information[i][self.environment.agents_last_choice[self.agents_id[i]]] += 1\n",
        "            # Updagte others preference based on your social learning strategy\n",
        "            if self.environment.agents_last_choice[self.agents_id[i]]== action:\n",
        "                same.append(self.agents_id[i])\n",
        "        \n",
        "        if self.id in same:\n",
        "            same.remove(self.id)\n",
        "        \n",
        "        if self.ilm.select_action() == action:\n",
        "            # print(\"$\"*10)\n",
        "            same.append(self.id)\n",
        "        \n",
        "        self.preferences -= self.lrs *  (u - self.total_mean_reward) * self.selecting_policy\n",
        "        for id in same:\n",
        "            index = self.id_2_ind[id]\n",
        "                                   \n",
        "            self.preferences[index] += self.lrs[index] * (u - self.total_mean_reward)\n",
        "        # self.preference = np.round(self.preference,2)\n",
        "        # d = np.sum(np.exp(self.preference))\n",
        "        # mask = np.ones(len(self.preference))*alpha\n",
        "        # self.preference = self.preference - mask * (Ri - self.mean_reward) * np.exp(self.preference)/d\n",
        "        # for index in same:\n",
        "        #     self.preference[index] = self.preference[index] + alpha * (Ri - self.mean_reward)\n",
        "        \n",
        "        p = np.exp(self.preferences - np.max(self.preferences))\n",
        "        self.selecting_policy = p / p.sum(axis=0)\n",
        "        for i in range(self.n):\n",
        "            self.preferences_history[self.agents_id[i]].append(self.selecting_policy[i])\n",
        "        \n",
        "        # p =  np.round(np.exp(np.round(self.preferences,2)),2)\n",
        "        # self.selecting_policy = p/np.sum(p)\n",
        "        # for j in range(len(p)):\n",
        "        #     if np.isnan(p[j]):\n",
        "        #         p[j] = 1\n",
        "        self.ilm.update(action, u)\n",
        "\n",
        "    def select_agent(self):\n",
        "        # select the agent based on selecting policy\n",
        "        agent_id = np.random.choice(self.agents_id, p = self.selecting_policy) \n",
        "        return agent_id \n",
        "\n",
        "    def select_action(self, sls, ind_mode):\n",
        "        agent_id = self.select_agent()\n",
        "        action = sls.select_action(self.social_information, agent_id) \n",
        "        if agent_id == self.id or ind_mode:\n",
        "            self.selecting_history.append(self.id) \n",
        "            # choose individual learning method\n",
        "            action = self.ilm.select_action()\n",
        "        else:\n",
        "            self.selecting_history.append(agent_id)\n",
        "\n",
        "        return action, agent_id\n",
        "\n",
        "    def take_action(self, sls, ind_mode = False):\n",
        "        if self.environment is None:\n",
        "            raise(\"env is not defined,\")\n",
        "        action, agent_id = self.select_action(sls, ind_mode)\n",
        "        obs, r, d, i = self.environment.step(action, self.id)\n",
        "        u = self.utility_function(r)\n",
        "        self.update(u, action, agent_id, ind_mode)\n",
        "        self.actions.append(action)        \n",
        "        return r, action, u\n",
        "\n",
        "    def get_actions(self):\n",
        "        return self.actions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "z5eF6fh2-xVD"
      },
      "outputs": [],
      "source": [
        "class TUCBAgent(AgentBase):\n",
        "    def __init__(self, c, environment = None, alpha = 1, beta = 1, gamma = 1,\n",
        "                 lr = None, lr_decay = 1,):\n",
        "        \"\"\"\n",
        "        c: a float, determine the degree of exploration \n",
        "        environment: the env object that agent interact with it\n",
        "        id: String or float or int, the name or the number of agent, used as a key in agents dict in environment\n",
        "        alpha, beta, gamma: float numbers are used for measuring utility based on prospect theory\n",
        "        lr = a float number, determine the rate of learning\n",
        "        lr_decay = a float number, determine the decay of learning rate \n",
        "        \"\"\"\n",
        "        super(TUCBAgent, self).__init__(lr, environment, alpha, beta, gamma, lr_decay)\n",
        "        self.c = c\n",
        "        self.trial = 0                                          #number of total trials \n",
        "        self.actions = []\n",
        "\n",
        "        if environment is not None:\n",
        "            self.n_actions = self.environment.n_actions()\n",
        "            self.n = len(self.environment.agents_last_choice)    #number of agents\n",
        "            self.social_information = np.zeros((self.n,self.n_actions))            \n",
        "            self.agents_id = list(environment.agents_last_choice.keys())\n",
        "            self.id_2_ind = {self.agents_id[i]:i for i in range(self.n)}\n",
        "            self.Q = np.zeros((self.n_actions,1))                #action value function(expected reward) for each arm\n",
        "            self.N = np.zeros((self.n_actions,1))                #number of doing each arm by agent\n",
        "            self.N_T = np.zeros((self.n_actions,1))              #number of doing each arm by target      \n",
        "            self.UCB = np.inf * np.ones((self.n_actions,1))      #Upper confidence bound for each arm\n",
        "            \n",
        "\n",
        "    def set_environment(self, env):\n",
        "        self.environment = env\n",
        "        self.trial = 0   \n",
        "        self.n_actions = self.environment.n_actions()\n",
        "        self.n = len(self.environment.agents_last_choice)    #number of agents\n",
        "        self.agents_id = list(env.agents_last_choice.keys())\n",
        "        self.id_2_ind = {self.agents_id[i]:i for i in range(self.n)}    \n",
        "        self.social_information = np.zeros((self.n,self.n_actions))\n",
        "        self.Q = np.zeros((self.n_actions,1))                #action value function(expected reward) for each arm\n",
        "        self.N = np.zeros((self.n_actions,1))                #number of doing each arm by agent\n",
        "        self.N_T = np.zeros((self.n_actions,1))              #number of doing each arm by target\n",
        "        self.UCB = np.zeros((self.n_actions,1))      #Upper confidence bound for each arm\n",
        "    \n",
        "\n",
        "    def update(self, action, u):\n",
        "        for i in range(self.n):\n",
        "            self.social_information[i][self.environment.agents_last_choice[self.agents_id[i]]] += 1\n",
        "\n",
        "        # update action values\n",
        "        self.trial += 1\n",
        "        self.N[action] = self.N[action] + 1\n",
        "        if self.lr is not None:\n",
        "            self.Q[action] += self.lr*(u-self.Q[action])\n",
        "            self.lr = self.lr * self.lr_decay\n",
        "        else:\n",
        "            self.Q[action] += (u-self.Q[action]) / self.N[action]\n",
        "\n",
        "\n",
        "    def select_action(self):\n",
        "        if self.trial < self.n_actions:\n",
        "            action = self.trial\n",
        "        else:        \n",
        "            T_optimism = np.sqrt(np.maximum((self.N_T - self.N)/(self.N_T),np.zeros((self.n_actions,1))))\n",
        "            # print(\"*\", T_optimism)\n",
        "            # print(\"**\",self.trial, np.sqrt(np.log(self.trial/self.N)))\n",
        "            # print(\"***\",self.Q)\n",
        "            self.UCB = self.Q + np.sqrt(self.c * np.log(self.trial + 1)/(self.N)) * T_optimism\n",
        "            action = np.random.choice(np.flatnonzero(self.UCB == self.UCB.max()))\n",
        "        return action \n",
        "\n",
        "    def take_action(self) -> (object, float, bool, object):\n",
        "        if self.environment is None:\n",
        "            raise(\"Env is not defined\")\n",
        "        action = self.select_action()\n",
        "        obs, r, d, i = self.environment.step(action, self.id)\n",
        "        u = self.utility_function(r)\n",
        "        self.update(action, u)\n",
        "        return r, action, u"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "ZJoAXkunuHYT"
      },
      "outputs": [],
      "source": [
        "class OUCBAgent(AgentBase):\n",
        "    def __init__(self, b1, b2, environment = None, alpha = 1, beta = 1, gamma = 1,\n",
        "                 lr = None, lr_decay = 1,):\n",
        "        \"\"\"\n",
        "        b1: a float, determine the degree of exploration \n",
        "        b2: a float, determine the degree of exploration\n",
        "        environment: the env object that agent interact with it\n",
        "        id: String or float or int, the name or the number of agent, used as a key in agents dict in environment\n",
        "        alpha, beta, gamma: float numbers are used for measuring utility based on prospect theory\n",
        "        lr = a float number, determine the rate of learning\n",
        "        lr_decay = a float number, determine the decay of learning rate \n",
        "        \"\"\"\n",
        "        super(OUCBAgent, self).__init__(lr, environment, alpha, beta, gamma, lr_decay)\n",
        "        self.b1 = b1\n",
        "        self.b2 = b2 \n",
        "        self.trial = 0                                          #number of total trials \n",
        "        self.actions = []\n",
        "\n",
        "        if environment is not None:\n",
        "            self.n_actions = self.environment.n_actions()\n",
        "            self.n = len(self.environment.agents_last_choice)    #number of agents\n",
        "            self.social_information = np.zeros((self.n,self.n_actions))            \n",
        "            self.agents_id = list(environment.agents_last_choice.keys())\n",
        "            self.id_2_ind = {self.agents_id[i]:i for i in range(self.n)}\n",
        "            self.Q = np.zeros((self.n_actions,1))                #action value function(expected reward) for each arm\n",
        "            self.N = np.zeros((self.n_actions,1))                #number of doing each arm by agent\n",
        "            self.N_T = np.zeros((self.n_actions,1))              #number of doing each arm by target      \n",
        "            self.UCB = np.inf * np.ones((self.n_actions,1))      #Upper confidence bound for each arm\n",
        "            \n",
        "\n",
        "    def set_environment(self, env):\n",
        "        self.environment = env\n",
        "        self.trial = 0   \n",
        "        self.n_actions = self.environment.n_actions()\n",
        "        self.n = len(self.environment.agents_last_choice)    #number of agents\n",
        "        self.agents_id = list(env.agents_last_choice.keys())\n",
        "        self.id_2_ind = {self.agents_id[i]:i for i in range(self.n)}    \n",
        "        self.social_information = np.zeros((self.n,self.n_actions))\n",
        "        self.Q = np.zeros((self.n_actions,1))                #action value function(expected reward) for each arm\n",
        "        self.N = np.zeros((self.n_actions,1))                #number of doing each arm by agent\n",
        "        self.N_T = np.zeros((self.n_actions,1))              #number of doing each arm by target\n",
        "        self.UCB = np.zeros((self.n_actions,1))      #Upper confidence bound for each arm\n",
        "    \n",
        "\n",
        "    def update(self, action, u):\n",
        "        for i in range(self.n):\n",
        "            self.social_information[i][self.environment.agents_last_choice[self.agents_id[i]]] += 1\n",
        "\n",
        "        # update action values\n",
        "        self.trial += 1\n",
        "        self.N[action] = self.N[action] + 1\n",
        "        if self.lr is not None:\n",
        "            self.Q[action] += self.lr*(u-self.Q[action])\n",
        "            self.lr = self.lr * self.lr_decay\n",
        "        else:\n",
        "            self.Q[action] += (u-self.Q[action]) / self.N[action]\n",
        "\n",
        "\n",
        "    def select_action(self):\n",
        "        if self.trial < self.n_actions:\n",
        "            action = self.trial\n",
        "        else:        \n",
        "            T_optimism = self.b1 + self.b2 * np.sqrt(np.maximum((self.N_T - self.N)/(self.trial),np.zeros((self.n_actions,1))))\n",
        "            # print(\"*\", T_optimism)\n",
        "            # print(\"**\",self.trial, np.sqrt(np.log(self.trial/self.N)))\n",
        "            # print(\"***\",self.Q)\n",
        "            self.UCB = self.Q + np.sqrt(2 * np.log(self.trial+ 1)/(self.N)) * T_optimism\n",
        "            action = np.random.choice(np.flatnonzero(self.UCB == self.UCB.max()))\n",
        "        return action \n",
        "\n",
        "    def take_action(self) -> (object, float, bool, object):\n",
        "        if self.environment is None:\n",
        "            raise(\"Env is not defined\")\n",
        "        action = self.select_action()\n",
        "        obs, r, d, i = self.environment.step(action, self.id)\n",
        "        u = self.utility_function(r)\n",
        "        self.update(action, u)\n",
        "        return r, action, u"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "hfjXLWimSNxm"
      },
      "outputs": [],
      "source": [
        "class FreeEnergySocialAgent(AgentBase):\n",
        "    \n",
        "    def __init__(self, ilm, a, b, lr = 0.1, env = None, alpha = 1,beta = 1,gamma = 1,):\n",
        "        \"\"\"\n",
        "        # TODO: Pi_TS == Pi_Behavioral? What is U? Pi_Behavioral should not be random.\n",
        "        # TODO: Instead of last action use the free energy best policy\n",
        "        # TODO: Baseline policy = epsilon-greedy individual \n",
        "        ilm: an individual learner object\n",
        "        alpha: an integer, Langrange multiplier of Eq. 20 or inverse temperature\n",
        "        beta: an integer, Langrange multiplier of Eq. 19 or inverse temperature\n",
        "        lr: an integer which set the learning rate\n",
        "        env: an environment object\n",
        "        \"\"\"\n",
        "        super(FreeEnergySocialAgent, self).__init__(lr, env,alpha = alpha,beta = beta,gamma = gamma)\n",
        "        self.ilm = ilm \n",
        "        self.lr = lr\n",
        "        self.t = 0 #trial\n",
        "        self.a = a\n",
        "        self.b = b \n",
        "        self.total_mean_reward = 0 \n",
        "        self.selecting_history = []\n",
        "        self.actions = []\n",
        "        # self.prob = 10\n",
        "\n",
        "        if self.environment is not None:\n",
        "            self.n = len(self.environment.agents_last_choice) # number of agents\n",
        "            self.k = self.environment.n_actions() # number of actions\n",
        "            self.FE = np.zeros(self.n) + 0.01\n",
        "            self.lrs = np.ones(self.n)*lr\n",
        "            self.social_information = np.ones((self.n,self.k))\n",
        "            # uniform initialization, (Others can be done, ourself 1 the others zero)\n",
        "            #self.selecting_policy = np.ones(self.n)/self.n\n",
        "            self.agents_id = list(env.agents_last_choice.keys())\n",
        "            self.id_2_ind = {self.agents_id[i]:i for i in range(self.n)}\n",
        "            self.FE_history  = {i:[] for i in self.agents_id}\n",
        "\n",
        "    def set_environment(self, env):\n",
        "        self.environment = env \n",
        "        self.n = len(self.environment.agents_last_choice) # number of agents\n",
        "        self.k = self.environment.n_actions() # number of actions\n",
        "        self.FE = np.zeros(self.n) + 0.01\n",
        "        self.lrs = np.ones(self.n)*self.lr\n",
        "        self.social_information = np.ones((self.n,self.k))\n",
        "        # uniform initialization, (Others can be done, ourself 1 the others zero)\n",
        "        # self.selecting_policy = np.ones(self.n)/self.n\n",
        "        self.agents_id = list(env.agents_last_choice.keys())\n",
        "        self.id_2_ind = {self.agents_id[i]:i for i in range(self.n)}\n",
        "        self.FE_history  = {i:[] for i in self.agents_id}\n",
        "        self.ilm.set_environment(env)\n",
        "\n",
        "    def FE_Calculator(self):\n",
        "        U = np.log(self.social_information/np.sum(self.social_information, axis = 1, keepdims = True)) \n",
        "        U_hat = U - (1/self.b)*(U - U[self.id_2_ind[self.id],:])\n",
        "        self.Pi_B = 1/self.k\n",
        "        Pi_star = self.Pi_B * np.exp(self.a * U_hat)\n",
        "        Pi_star = Pi_star / np.sum(Pi_star, axis = 1, keepdims = True)\n",
        "        FE = np.sum(Pi_star * ((1/self.a)*np.log(Pi_star/self.Pi_B) - U_hat), axis = 1)\n",
        "        return FE\n",
        "    \n",
        "    def update(self, u, action, agent_id, ind_mode):\n",
        "        self.t += 1\n",
        "        #self.total_mean_reward += (u - self.total_mean_reward)/self.t\n",
        "\n",
        "        for i in range(self.n):\n",
        "            self.social_information[i][self.environment.agents_last_choice[self.agents_id[i]]] += 1\n",
        "        \n",
        "        self.FE = self.FE_Calculator()\n",
        "        self.FE_history[self.agents_id[i]].append(self.FE)\n",
        "        self.ilm.update(action, u)\n",
        "\n",
        "    def select_agent(self):\n",
        "        # select the agent based on selecting policy\n",
        "        agent_id = np.argmin(self.FE) \n",
        "        return int(agent_id) \n",
        "\n",
        "    def select_action(self, sls, ind_mode):\n",
        "        agent_id = self.select_agent()\n",
        "        action = sls.select_action(self.social_information, agent_id) \n",
        "        if agent_id == self.id or ind_mode:\n",
        "            self.selecting_history.append(self.id) \n",
        "            # choose individual learning method\n",
        "            action = self.ilm.select_action()\n",
        "        else:\n",
        "            self.selecting_history.append(agent_id)\n",
        "\n",
        "        return action, agent_id\n",
        "\n",
        "    def take_action(self, sls, ind_mode = False):\n",
        "        if self.environment is None:\n",
        "            raise(\"env is not defined,\")\n",
        "        action, agent_id = self.select_action(sls, ind_mode)\n",
        "        obs, r, d, i = self.environment.step(action, self.id)\n",
        "        u = self.utility_function(r)\n",
        "\n",
        "        self.update(u, action, agent_id, ind_mode)\n",
        "        self.actions.append(action)        \n",
        "        return r, action, u\n",
        "\n",
        "    def get_actions(self):\n",
        "        return self.actions    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "ARUX2qwyPhJS"
      },
      "outputs": [],
      "source": [
        "class MetaSocialLearnerAgent(AgentBase):\n",
        "\n",
        "    def __init__(self, slm, sls, env = None, alpha = 1,beta = 1,gamma = 1, lr = None):\n",
        "        \"\"\"\n",
        "        slm: a social learner object\n",
        "        sls: a social strategy object\n",
        "        env: an environment object \n",
        "        \"\"\"\n",
        "        super(MetaSocialLearnerAgent, self).__init__(lr, environment = env,alpha = alpha,beta = beta,gamma = gamma) \n",
        "        self.slm = slm\n",
        "        self.sls = sls\n",
        "        self.ind_mode = False \n",
        "\n",
        "    def set_environment(self, env):\n",
        "        self.environment = env\n",
        "        self.sls.set_environment(env)\n",
        "        self.slm.set_environment(env)\n",
        "    \n",
        "    def set_id(self, id):\n",
        "        self.id = id\n",
        "        self.slm.id = id\n",
        "\n",
        "    def update(self, u, action):\n",
        "        # Novelty/Surprise\n",
        "        # Volatileness\n",
        "        # Uncertainty\n",
        "        return \n",
        "    \n",
        "    def select_sls(self):\n",
        "        pass \n",
        "    \n",
        "    def select_slm(self):\n",
        "        pass\n",
        "\n",
        "    def take_action(self):\n",
        "        # Based on Novelty/Surprise, Volatileness, Uncertainty\n",
        "        # Select social learning strategy\n",
        "        # Select social learning method using Free energy or predefined rules\n",
        "        if self.environment is None: \n",
        "            raise(\"environment is not defined\")\n",
        "        r, action, u = self.slm.take_action(self.sls, self.ind_mode)\n",
        "        self.update(u,action)\n",
        "        \n",
        "        return r, action, u"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "cSxgFpiXPrKQ"
      },
      "outputs": [],
      "source": [
        "class agents_population():\n",
        "    def __init__(self, ):\n",
        "        \"\"\"\n",
        "        should return a list of agent objects\n",
        "        \"\"\"\n",
        "        pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "x8uI_PJjeeht"
      },
      "outputs": [],
      "source": [
        "class environemnt_class():\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        should return a list of environment objects\n",
        "        \"\"\"\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SocialBanditLearning():\n",
        "    def __init__(self, pop_agents, env_class, n_trials, n_reps):\n",
        "        \"\"\"\n",
        "        pop_agents: a dict which its keys are agents id and its values are agent obejcts\n",
        "        env_class: a list of environment objects\n",
        "        n_reps: an integer, number of repetiotions\n",
        "        n_trials: an integer, number of trials \n",
        "        \"\"\"\n",
        "        self.pop_agents = pop_agents\n",
        "        self.env_class = env_class\n",
        "        self.n_trials = n_trials \n",
        "        self.n_reps = n_reps \n",
        "        self.n_agents = len(pop_agents)\n",
        "        self.n_envs = len(env_class)\n",
        "\n",
        "        self.best_actions, self.best_exp_u = self.calculate_bests()    \n",
        "        \n",
        "        self.action_history = np.zeros((self.n_agents, self.n_envs, self.n_reps, self.n_trials))\n",
        "        self.utility_history = np.zeros((self.n_agents, self.n_envs, self.n_reps, self.n_trials)) \n",
        "        \n",
        "        self.regret = np.zeros((self.n_agents, self.n_envs, self.n_reps, self.n_trials))\n",
        "        self.perc_opt_act = np.zeros((self.n_agents, self.n_envs, self.n_reps, self.n_trials))\n",
        "        self.average_utils = np.zeros((self.n_agents, self.n_envs, self.n_reps, self.n_trials))\n",
        "        \n",
        "    def best_max(self, env, agent): \n",
        "        if (agent.alpha, agent.beta, agent.gamma) == (1,1,1):\n",
        "            EU = np.array([r.mean for r in env.arms_rewards])\n",
        "        else:\n",
        "            EU = np.array([r.exp_u(agent) for r in env.arms_rewards])\n",
        "        max_ind = np.random.choice(np.flatnonzero(EU == EU.max()))\n",
        "        return max_ind, EU.max() \n",
        "\n",
        "    def calculate_bests(self):\n",
        "        best_actions = np.zeros((self.n_envs, self.n_agents))\n",
        "        best_exp_u = np.zeros((self.n_envs, self.n_agents))\n",
        "        for i, env in enumerate(self.env_class):\n",
        "            for j, agent in enumerate(self.pop_agents.values()):\n",
        "                best_actions[i,j], best_exp_u[i,j] = self.best_max(env, agent)\n",
        "        \n",
        "        return best_actions, best_exp_u\n",
        "\n",
        "    def run(self):\n",
        "        for i, env in enumerate(self.env_class):\n",
        "            for id in self.pop_agents.keys():\n",
        "                env.add_agent(id)\n",
        "                self.pop_agents[id].set_id(id)\n",
        "\n",
        "            \n",
        "            for r in tqdm(range(self.n_reps)):\n",
        "                sum_utils = np.zeros((self.n_agents))\n",
        "                opt_act_count = np.zeros((self.n_agents))\n",
        "                \n",
        "                for agent in self.pop_agents.values():\n",
        "                    agent.set_environment(env)\n",
        "\n",
        "                for t in range(self.n_trials):                    \n",
        "                    for j, agent in enumerate(self.pop_agents.values()):\n",
        "                        rew, act, u = agent.take_action()\n",
        "                        self.action_history[j,i,r,t] = act\n",
        "                        self.utility_history[j,i,r,t] = u\n",
        "                        sum_utils[j] += u\n",
        "                        self.average_utils[j,i,r,t] = u\n",
        "                        # opt_act_count[j] += (self.action_history[i,j,r,t] == self.best_actions[i,j]).astype(int)\n",
        "\n",
        "                    env.update_selected(self.action_history[:,i,r,t].astype(int), list(self.pop_agents.keys()))\n",
        "                    \n",
        "                    self.regret[:,i,r,t] = (t+1)*self.best_exp_u[i,:] - sum_utils\n",
        "                    self.perc_opt_act[:,i,r,t] = (self.action_history[:,i,r,t] == self.best_actions[i,:]).astype(int)\n",
        "                    # self.perc_opt_act[i,:,r,t] = opt_act_count / (t+1) \n",
        "                    \n",
        "                env.reset()\n",
        "        \n",
        "        return self.perc_opt_act, self.regret, self.average_utils\n",
        "    \n",
        "    def regret_visulization(self):\n",
        "        \"\"\"\n",
        "        compare to individual learning\n",
        "        \"\"\"\n",
        "\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "class utils:\n",
        "    def __init__(self):\n",
        "        self.x = \"print\"\n",
        "        #drive.mount('/content/gdrive')\n",
        "\n",
        "    def Visual(self, data, n_trials, save = False, name = \"\", std = True, limit = True, line = True, label = \"difference of the percent of best action selection social and individual\"):\n",
        "        fig, ax = plt.subplots()\n",
        "        clrs = sns.color_palette(\"husl\", len(data.keys()))\n",
        "        with sns.axes_style(\"darkgrid\"):\n",
        "            epochs = list(range(n_trials))\n",
        "            for (x, c) in zip(data.keys(),clrs):\n",
        "                meanst = np.mean(data[x],axis = 0)\n",
        "                sdt = 2*np.std(data[x], axis = 0, ddof = 0)/np.sqrt(np.shape(data[x])[0])\n",
        "                ax.plot(epochs, meanst, label=x, c=c)\n",
        "                if std:\n",
        "                    ax.fill_between(epochs, meanst-sdt, meanst+sdt ,alpha=0.3, facecolor=c)\n",
        "            if line:\n",
        "                ax.plot(epochs, np.zeros(n_trials), linestyle='dotted', c='black')\n",
        "            ax.legend()\n",
        "            plt.xlabel(\"trial\")\n",
        "            plt.ylabel(label)\n",
        "            if limit:\n",
        "                plt.ylim([0,1])\n",
        "        if save:\n",
        "            fig.savefig(name, dpi=1200)\n",
        "\n",
        "    def save(self, data, name):\n",
        "        np.save(name, data) \n",
        "    \n",
        "    def load(self, name):\n",
        "        return np.load(name,allow_pickle='TRUE').item()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Experiment"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Gaussian"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8804\\607836119.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0menv_class\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[0msbl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSocialBanditLearning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpop_agents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[0mperc_opt_act\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage_utils\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msbl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[0mbest_actions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_exp_u\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msbl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalculate_bests\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8804\\3072635814.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, pop_agents, env_class, n_trials, n_reps)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_envs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv_class\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_actions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_exp_u\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalculate_bests\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_history\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_agents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_envs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_reps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_trials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8804\\3072635814.py\u001b[0m in \u001b[0;36mcalculate_bests\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv_class\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop_agents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m                 \u001b[0mbest_actions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_exp_u\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_max\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mbest_actions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_exp_u\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8804\\3072635814.py\u001b[0m in \u001b[0;36mbest_max\u001b[1;34m(self, env, agent)\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[0mEU\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marms_rewards\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m             \u001b[0mEU\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp_u\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magent\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marms_rewards\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[0mmax_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEU\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mEU\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmax_ind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEU\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8804\\3072635814.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[0mEU\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marms_rewards\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m             \u001b[0mEU\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp_u\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magent\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marms_rewards\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[0mmax_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEU\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mEU\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmax_ind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEU\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8804\\2494263978.py\u001b[0m in \u001b[0;36mexp_u\u001b[1;34m(self, agent, n_samples)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexp_u\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mutility_distribution\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutility_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mutility_distribution\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8804\\2494263978.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexp_u\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mutility_distribution\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutility_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mutility_distribution\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8804\\3839350413.py\u001b[0m in \u001b[0;36mutility_function\u001b[1;34m(self, reward)\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0mutility_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreward\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreward\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[0mu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreward\u001b[0m \u001b[1;33m**\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "num_agents = 100 \n",
        "pop_agents = {}\n",
        "\n",
        "ALPHA_MEAN = 0.6\n",
        "ALPHA_STD = 0.1\n",
        "\n",
        "BETA_MEAN = 0.6\n",
        "BETA_STD = 0.1\n",
        "\n",
        "GAMMA_MEAN = 1.6\n",
        "GAMMA_STD = 0.25\n",
        "\n",
        "SEED = 313\n",
        "\n",
        "np.random.seed(SEED)\n",
        "\n",
        "for i in range(num_agents):\n",
        "    a = np.random.normal(loc= ALPHA_MEAN, scale= ALPHA_STD)\n",
        "    b = np.random.normal(loc= BETA_MEAN, scale= BETA_STD)\n",
        "    c = np.random.normal(loc= GAMMA_MEAN, scale= GAMMA_STD)\n",
        "    pop_agents[i] = EpsilonGreedyAgent(epsilon = 0.1, alpha = a, beta = b, gamma = c)\n",
        "\n",
        "\n",
        "num_arms = [2, 10, 50 ,100]\n",
        "\n",
        "env_class = []\n",
        " \n",
        "for k in num_arms:\n",
        "    sigma = 0.5/k\n",
        "    optimality_gaps = [6*sigma, 3*sigma, sigma]\n",
        "    for opt_gap in optimality_gaps: \n",
        "        reward_means = [-1.5 + i * opt_gap for i in range(k)]\n",
        "        Reward = [GaussianReward(reward_means[i], sigma) for i in range(k)]\n",
        "        env = SocialMutliArmedBanditEnvironment(Reward, 10000)\n",
        "        env_class.append(env)\n",
        "\n",
        "sbl = SocialBanditLearning(pop_agents, env_class, 10000, 50)\n",
        "perc_opt_act, regret, average_utils = sbl.run()\n",
        "best_actions, best_exp_u = sbl.calculate_bests() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Using colors for defining optimal action "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'perc_opt_act' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8804\\415673508.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mperc_opt_act\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mavg_perc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mperc_opt_act\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mavg_perc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'perc_opt_act' is not defined"
          ]
        }
      ],
      "source": [
        "print(perc_opt_act.shape)\n",
        "avg_perc = np.average(perc_opt_act, axis = 0)\n",
        "print(avg_perc.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'perc_opt_act' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8804\\317914671.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mavg_perc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mperc_opt_act\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mavg_perc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m900\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# np.asarray(avg_perc > 0.7).nonzero()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'perc_opt_act' is not defined"
          ]
        }
      ],
      "source": [
        "avg_perc = np.average(perc_opt_act[0,0,:,:],axis = 0)\n",
        "avg_perc[900]\n",
        "# np.asarray(avg_perc > 0.7).nonzero()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'perc_opt_act' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8804\\487987725.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mstds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mperc_opt_act\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mmean_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mstd_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'perc_opt_act' is not defined"
          ]
        }
      ],
      "source": [
        "means = []\n",
        "stds = []\n",
        "\n",
        "for i in range(perc_opt_act.shape[1]):\n",
        "    mean_t = []\n",
        "    std_t = []\n",
        "    for j in  range(perc_opt_act.shape[0]):\n",
        "        avg_perc = np.average(perc_opt_act[j,i,:,:],axis = 0)\n",
        "        std_perc = np.std(perc_opt_act[j,i,:,:],axis = 0)\n",
        "        a = list(np.asarray(avg_perc > 0.7).nonzero()[0])\n",
        "        a.append(-1)\n",
        "        mean_t.append(a[0])\n",
        "        std_t.append(std_perc[a[0]])\n",
        "    \n",
        "    means.append(mean_t)\n",
        "    stds.append(std_t)\n",
        "    plt.bar(list(range(1,101)), mean_t, yerr = std_t)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('results/budget_gaussian_means.pkl', 'wb') as f:\n",
        "    pickle.dump(means, f)\n",
        "\n",
        "with open('results/budget_gaussian_stds.pkl', 'wb') as f:\n",
        "    pickle.dump(stds, f)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Bernouli "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "AGENTS_COUNT = 100\n",
        "\n",
        "AGENT_EPSILON = 0.1\n",
        "\n",
        "EPISODE_MAX_LENGTH = 1000\n",
        "\n",
        "EPS = 0.0001\n",
        "SEED = 313\n",
        "REPETITION = 50\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ind_simulate(main_agent, rewards, trials=EPISODE_MAX_LENGTH, \n",
        "             epsilon=AGENT_EPSILON, repetition=REPETITION):\n",
        "    \n",
        "    taken_actions = np.zeros((repetition, trials))\n",
        "    given_rewards = np.zeros((repetition, trials))\n",
        "    after_rewards = np.zeros((repetition, trials))\n",
        "    \n",
        "    for r in range(repetition):\n",
        "        environment = MultiArmedBanditEnvironment(rewards=rewards)\n",
        "        agent = EpsilonGreedyAgent(id='0', environment=environment, utility_function=main_agent, epsilon=epsilon, part_of_agent= False)\n",
        "        environment.submit()\n",
        "        for trial in range(trials):\n",
        "            _, reward, _, _, action = agent.take_action()\n",
        "            taken_actions[r][trial] = action\n",
        "            given_rewards[r][trial] = reward\n",
        "            after_rewards[r][trial] = main_agent.apply(reward)\n",
        "            \n",
        "    return taken_actions, given_rewards, after_rewards"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_rewards(values, arms_probabilities):\n",
        "    rewards = []\n",
        "    for arm_probabilities in arms_probabilities:\n",
        "        reward = MultinomialReward(values=values, probabilities=arm_probabilities)\n",
        "        rewards.append(reward)\n",
        "    return rewards"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "reward_values = [[-2.,1.],[-20.,10.],[-200.,100.]]\n",
        "REWARD_PROB_ARMS = [\n",
        "    [0.1, 0.9],\n",
        "    [0.2, 0.8],\n",
        "    [0.3, 0.7],\n",
        "    [0.4, 0.6],\n",
        "    [0.5, 0.5],\n",
        "    [0.6, 0.4],\n",
        "    [0.7, 0.3],\n",
        "    [0.8, 0.2],\n",
        "    [0.9, 0.1],\n",
        "    [1.0, 0.0]\n",
        "]\n",
        "\n",
        "rewards = []\n",
        "for REWARD_VALUES in reward_values:\n",
        "    REWARDS = get_rewards(REWARD_VALUES, REWARD_PROB_ARMS)\n",
        "    rewards.append(REWARDS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "64731a578d944e86b16e1353703867ef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8c71e3fe0ab646c4a6b5499e157c9de6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1b5fc24fe8c74af68df49191db863209",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "AGENT_CREATOR2 = AgentCreator(seed= SEED)\n",
        "POP_AGENTS2 = AGENT_CREATOR2.create_agents(100)\n",
        "\n",
        "means2 = []\n",
        "stds2 = []\n",
        "\n",
        "for rews in rewards:\n",
        "    mean_t2 = []\n",
        "    std_t2 = []\n",
        "    for agent in tqdm(POP_AGENTS2):        \n",
        "        taken_actions, given_rewards, after_rewards = ind_simulate(main_agent=agent, rewards=rews)\n",
        "        desired_action = 0\n",
        "        avg_perc2 = np.mean(taken_actions == desired_action, axis=0)\n",
        "        std_perc2 = np.std(taken_actions == desired_action, axis = 0)\n",
        "        a = list(np.asarray(avg_perc2 > 0.7).nonzero()[0])\n",
        "        a.append(-1)\n",
        "        mean_t2.append(a[0])\n",
        "        std_t2.append(std_perc2[a[0]])\n",
        "    \n",
        "    means2.append(mean_t2)\n",
        "    stds2.append(std_t2)\n",
        "    plt.bar(list(range(1,101)), mean_t2, yerr = std_t2, alpha = 0.7)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 50/50 [06:34<00:00,  7.88s/it]\n",
            "100%|| 50/50 [06:47<00:00,  8.15s/it]\n",
            "100%|| 50/50 [06:49<00:00,  8.19s/it]\n"
          ]
        }
      ],
      "source": [
        "num_agents = 100 \n",
        "pop_agents2 = {}\n",
        "\n",
        "ALPHA_MEAN = 0.6\n",
        "ALPHA_STD = 0.1\n",
        "\n",
        "BETA_MEAN = 0.6\n",
        "BETA_STD = 0.1\n",
        "\n",
        "GAMMA_MEAN = 1.6\n",
        "GAMMA_STD = 0.25\n",
        "\n",
        "SEED = 313\n",
        "\n",
        "np.random.seed(SEED)\n",
        "\n",
        "for i in range(num_agents):\n",
        "    a = np.random.normal(loc= ALPHA_MEAN, scale= ALPHA_STD)\n",
        "    b = np.random.normal(loc= BETA_MEAN, scale= BETA_STD)\n",
        "    c = np.random.normal(loc= GAMMA_MEAN, scale= GAMMA_STD)\n",
        "    pop_agents2[i] = EpsilonGreedyAgent(epsilon = 0.1, alpha = a, beta = b, gamma = c)\n",
        "\n",
        "\n",
        "env_class2 = []\n",
        "num_arms = [10]\n",
        "optimality_gaps = [1]\n",
        "reward_values = [(-2,1),(-20,10),(-200,100)]\n",
        " \n",
        "for k in num_arms:\n",
        "    for opt_gap in optimality_gaps: \n",
        "        for rew_val in reward_values:\n",
        "            Reward = [MultinomialReward([rew_val[0], rew_val[1]], [(i+1)/(opt_gap * k), 1- ((i+1)/(opt_gap * k))]) for i in range(k)]\n",
        "            env = SocialMutliArmedBanditEnvironment(Reward, 10000)\n",
        "            env_class2.append(env)\n",
        "\n",
        "sbl2 = SocialBanditLearning(pop_agents2, env_class2, 1000, 50)\n",
        "perc_opt_act2, regret2, average_utils2 = sbl2.run()\n",
        "best_actions2, best_exp_u2 = sbl2.calculate_bests() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGdCAYAAAA44ojeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAs9UlEQVR4nO3df1RU953/8RfyY5TBgaJlBlYwNkmjRI1WDU6TTd1IRWVtsuHsaVIjJOHoVxdjlK6xtMYk2gTX7cnPQ9T2WEm3UlN6YrJhE41igs2Kv0isRrI0Ws9iowO78cDIpILC/f7Rw13HoHFwYO4Mz8c595yZez/MvOejDi8/93M/N8owDEMAAAAWMijUBQAAAFyOgAIAACyHgAIAACyHgAIAACyHgAIAACyHgAIAACyHgAIAACyHgAIAACwnJtQF9EZXV5dOnz6toUOHKioqKtTlAACAa2AYhs6dO6e0tDQNGnT1MZKwDCinT59Wenp6qMsAAAC9cOrUKY0YMeKqbcIyoAwdOlTSXz+gw+EIcTUAAOBaeL1epaenm7/Hr+a6AsratWtVUlKixx57TC+88IIk6fz58/rhD3+orVu3qr29XTk5OXrllVfkdDrNn2tsbNSiRYv03nvvKSEhQQUFBSotLVVMzLWV031ax+FwEFAAAAgz1zI9o9eTZA8ePKiNGzdq/PjxfvuXLVumt956S5WVlaqpqdHp06d13333mcc7OzuVm5urjo4O7d27V6+++qrKy8u1atWq3pYCAAAiTK8CSltbm+bOnatf/OIX+trXvmbub21t1aZNm/Tcc8/p7rvv1qRJk7R582bt3btX+/btkyS9++67qq+v169//WtNmDBBs2bN0po1a1RWVqaOjo7gfCoAABDWehVQioqKlJubq+zsbL/9dXV1unDhgt/+0aNHKyMjQ7W1tZKk2tpajRs3zu+UT05Ojrxer44dO9bj+7W3t8vr9fptAAAgcgU8B2Xr1q368MMPdfDgwS8d83g8iouLU1JSkt9+p9Mpj8djtrk0nHQf7z7Wk9LSUj399NOBlgoAAMJUQCMop06d0mOPPaYtW7Zo8ODBfVXTl5SUlKi1tdXcTp061W/vDQAA+l9AAaWurk7Nzc361re+pZiYGMXExKimpkYvvfSSYmJi5HQ61dHRoZaWFr+fa2pqksvlkiS5XC41NTV96Xj3sZ7YbDbzih2u3AEAIPIFFFCmT5+uo0eP6vDhw+Y2efJkzZ0713wcGxur6upq82caGhrU2Ngot9stSXK73Tp69Kiam5vNNjt37pTD4VBmZmaQPhYAAAhnAc1BGTp0qMaOHeu3z263a9iwYeb+wsJCFRcXKzk5WQ6HQ48++qjcbremTp0qSZoxY4YyMzM1b948rVu3Th6PRytXrlRRUZFsNluQPhYAAAhnQV9J9vnnn9egQYOUl5fnt1Bbt+joaFVVVWnRokVyu92y2+0qKCjQ6tWrg10KAAAIU1GGYRihLiJQXq9XiYmJam1tZT4KAABhIpDf371eSRYAAKCvEFAAAIDlEFAAAIDlEFAAAIDlEFBw3Xw+n6KiohQVFSWfzxfqcgAAEYCreHDdCsv978u06aEpIaoEAGBlXMUDAADCGgEFAABYDgEFAABYDgEFAABYDgEFAABYDgEFAABYDgEFAABYDgEFAABYDgEFsAhW5AWA/xMT6gIA/NWSyno9svmAJMlut4e4GgAILUZQAACA5RBQAACA5RBQAACA5RBQAACA5RBQAACA5RBQAACA5RBQAACA5RBQAACA5RBQAACA5RBQAACA5RBQAACA5RBQAADXLX/jHvNml/kb94S6HEQAbhYIALhusbYh5s0ugWBgBAUAAFgOAQUAAFgOAQUAAFgOAQUALM7n85kTUH0+X6jLAfoFk2QBwOKWVNabE1CXVNZr00NTQlwR0PcCGkFZv369xo8fL4fDIYfDIbfbrXfeecc8Pm3aNDPld28LFy70e43Gxkbl5uYqPj5eKSkpWr58uS5evBicTwMAACJCQCMoI0aM0Nq1a3XzzTfLMAy9+uqruueee/TRRx/p1ltvlSTNnz9fq1evNn8mPj7efNzZ2anc3Fy5XC7t3btXZ86cUX5+vmJjY/Xss88G6SMBAIBwF1BAmTNnjt/zZ555RuvXr9e+ffvMgBIfHy+Xy9Xjz7/77ruqr6/Xrl275HQ6NWHCBK1Zs0YrVqzQU089pbi4uF5+DAAAEEl6PUm2s7NTW7dulc/nk9vtNvdv2bJFw4cP19ixY1VSUqIvvvjCPFZbW6tx48bJ6XSa+3JycuT1enXs2LErvld7e7u8Xq/fBgAAIlfAk2SPHj0qt9ut8+fPKyEhQdu2bVNmZqYk6Qc/+IFGjhyptLQ0HTlyRCtWrFBDQ4Nef/11SZLH4/ELJ5LM5x6P54rvWVpaqqeffjrQUgEAQJgKOKDccsstOnz4sFpbW/W73/1OBQUFqqmpUWZmphYsWGC2GzdunFJTUzV9+nSdOHFCN954Y6+LLCkpUXFxsfnc6/UqPT29168HAACsLeBTPHFxcbrppps0adIklZaW6rbbbtOLL77YY9usrCxJ0vHjxyVJLpdLTU1Nfm26n19p3ook2Ww288qh7g0AAESu616oraurS+3t7T0eO3z4sCQpNTVVkuR2u3X06FE1NzebbXbu3CmHw2GeJgIAAAjoFE9JSYlmzZqljIwMnTt3ThUVFXr//fe1Y8cOnThxQhUVFZo9e7aGDRumI0eOaNmyZbrrrrs0fvx4SdKMGTOUmZmpefPmad26dfJ4PFq5cqWKiopks9n65AMCAIDwE1BAaW5uVn5+vs6cOaPExESNHz9eO3bs0He/+12dOnVKu3bt0gsvvCCfz6f09HTl5eVp5cqV5s9HR0erqqpKixYtktvtlt1uV0FBgd+6KQAAAAEFlE2bNl3xWHp6umpqar7yNUaOHKm33347kLcFAAADDDcLBAAAlkNAAQAAlkNAAQBYls/nM28+m79xT6jLQT8KeKE2AAD6i91u1yObD4S6DIQAIygAAMByCCgAAMByCCgAAMByCCgAAMByCCgAAMByCCgAAMByCCgAAMByCCgAAMByCCgAAMByCCgAAMByCCgRKn/jHu5fAQAIW9yLJ0LF2oZw/woAQNhiBAUAAFgOAQUAAFgOAQUAAFgOAQVAxPL5fOZkcZ/PF+pyAASASbIAIpbdbjcniy+prNemh6aEuCIA14oRFAAAYDkEFAAAYDkEFAAAYDkEFAAAYDkEFAAAYDkEFAAAYDkEFAAAYDkEFAAAYDkEFAAAYDkEFAAAYDkEFAAABpj8jXvM+1Tlb9wT6nJ6xL14AAAYYGJtQ8z7VFkVIygAAMByCCgAAMByAgoo69ev1/jx4+VwOORwOOR2u/XOO++Yx8+fP6+ioiINGzZMCQkJysvLU1NTk99rNDY2Kjc3V/Hx8UpJSdHy5ct18eLF4HwaAAAQEQIKKCNGjNDatWtVV1enQ4cO6e6779Y999yjY8eOSZKWLVumt956S5WVlaqpqdHp06d13333mT/f2dmp3NxcdXR0aO/evXr11VdVXl6uVatWBfdTAQCAsBbQJNk5c+b4PX/mmWe0fv167du3TyNGjNCmTZtUUVGhu+++W5K0efNmjRkzRvv27dPUqVP17rvvqr6+Xrt27ZLT6dSECRO0Zs0arVixQk899ZTi4uKC98kAAEDY6vUclM7OTm3dulU+n09ut1t1dXW6cOGCsrOzzTajR49WRkaGamtrJUm1tbUaN26cnE6n2SYnJ0der9cchelJe3u7vF6v3wYAACJXwAHl6NGjSkhIkM1m08KFC7Vt2zZlZmbK4/EoLi5OSUlJfu2dTqc8Ho8kyePx+IWT7uPdx66ktLRUiYmJ5paenh5o2QAQNnw+n7lGhc/nC3U5QEgEvA7KLbfcosOHD6u1tVW/+93vVFBQoJqamr6ozVRSUqLi4mLzudfrJaQAiFhLKuvNNSrsdnuIqwFCI+CAEhcXp5tuukmSNGnSJB08eFAvvviivv/976ujo0MtLS1+oyhNTU1yuVySJJfLpQMH/BeG6b7Kp7tNT2w2m2w2W6ClAgCAMHXd66B0dXWpvb1dkyZNUmxsrKqrq81jDQ0NamxslNvtliS53W4dPXpUzc3NZpudO3fK4XAoMzPzeksBAAARIqARlJKSEs2aNUsZGRk6d+6cKioq9P7772vHjh1KTExUYWGhiouLlZycLIfDoUcffVRut1tTp06VJM2YMUOZmZmaN2+e1q1bJ4/Ho5UrV6qoqIgRkn6Qv3GP/m3hdyRJbW1tDB0DACwroIDS3Nys/Px8nTlzRomJiRo/frx27Nih7373u5Kk559/XoMGDVJeXp7a29uVk5OjV155xfz56OhoVVVVadGiRXK73bLb7SooKNDq1auD+6nQo0vvvUA4AQBYWUABZdOmTVc9PnjwYJWVlamsrOyKbUaOHKm33347kLcFAAADDPfiAQAAlkNAAQAAlkNAAQAAlkNAAQAAlkNAAQAAlkNAAQAAlkNAAQAAlkNAAQAAlkNAAQAAlkNAAQAAlkNAAQCYfD6foqKiFBUVJZ/PF+pyMIAFdC8eAEBkW1JZb95UdEllvTY9NCXEFWGgYgQFAABYDgEFAABYDgEFAABYDgEFAABYDgEFAABYDgEFAABYDgEFAABYDgEFAABYDgEFAABYDgEFAABYDgEFAABYDgEFAABYDgEFAABYDgEFAABYDgEFAABYDgEFAABYDgEFAABYTkyoCwAA9I/C8oN+zzc9NCVElQBfjREUAABgOQQUAABgOQQUAABgOQQUAABgOQEFlNLSUk2ZMkVDhw5VSkqK7r33XjU0NPi1mTZtmqKiovy2hQsX+rVpbGxUbm6u4uPjlZKSouXLl+vixYvX/2kAAEBECOgqnpqaGhUVFWnKlCm6ePGifvzjH2vGjBmqr6+X3W43282fP1+rV682n8fHx5uPOzs7lZubK5fLpb179+rMmTPKz89XbGysnn322SB8JAAAEO4CCijbt2/3e15eXq6UlBTV1dXprrvuMvfHx8fL5XL1+Brvvvuu6uvrtWvXLjmdTk2YMEFr1qzRihUr9NRTTykuLq4XHwMAAESS65qD0traKklKTk72279lyxYNHz5cY8eOVUlJib744gvzWG1trcaNGyen02nuy8nJkdfr1bFjx3p8n/b2dnm9Xr8NAABErl4v1NbV1aWlS5fqjjvu0NixY839P/jBDzRy5EilpaXpyJEjWrFihRoaGvT6669Lkjwej184kWQ+93g8Pb5XaWmpnn766d6WCgAAwkyvA0pRUZE+/vhjffDBB377FyxYYD4eN26cUlNTNX36dJ04cUI33nhjr96rpKRExcXF5nOv16v09PTeFQ4AACyvV6d4Fi9erKqqKr333nsaMWLEVdtmZWVJko4fPy5Jcrlcampq8mvT/fxK81ZsNpscDoffBgAAIldAAcUwDC1evFjbtm3T7t27NWrUqK/8mcOHD0uSUlNTJUlut1tHjx5Vc3Oz2Wbnzp1yOBzKzMwMpBwAABChAjrFU1RUpIqKCr355psaOnSoOWckMTFRQ4YM0YkTJ1RRUaHZs2dr2LBhOnLkiJYtW6a77rpL48ePlyTNmDFDmZmZmjdvntatWyePx6OVK1eqqKhINpst+J8QAACEnYBGUNavX6/W1lZNmzZNqamp5vbaa69JkuLi4rRr1y7NmDFDo0eP1g9/+EPl5eXprbfeMl8jOjpaVVVVio6Oltvt1oMPPqj8/Hy/dVMAAMDAFtAIimEYVz2enp6umpqar3ydkSNH6u233w7krQFEMJ/Pp4SEBElSW1ub38KPVhEONQKRpNdX8QBAsCyprNcjmw+Yjzc9NCXEFX3ZpTUSToC+x80CAQCA5RBQAACA5RBQAACA5RBQAACA5TBJFohwheUH/Z5bcQIqAFyOERQAAGA5BBQAAGA5BBQAA4rP51NUVJSioqLk8/lCXQ6AK2AOCoABJRwWhQPACAoAALAgAsplLh3+zd+4J9TlAAAwIHGK5zJ2u90c/gUAAKHBCAoAALAcAgoAALAcAgoAALAcAgoAALAcAgoAAEHGgoDXj6t4AAAIsksXBLTb7SGuJjwxggIAACyHgAIAACyHgAIAACyHgAIAACyHgAIAACyHq3gAALiCwvKDfs83PTQlRJUMPASUAczn8ykhIUGS1NbWxqVwAxhfwgCshoAygF16nf6Synp+KQEALIM5KAAAwHIIKAAAwHIIKAAAwHIIKAAAwHIIKAAAwHIIKAAAwHIIKAAAwHICCiilpaWaMmWKhg4dqpSUFN17771qaGjwa3P+/HkVFRVp2LBhSkhIUF5enpqamvzaNDY2Kjc3V/Hx8UpJSdHy5ct18eLF6/80AAAgIgQUUGpqalRUVKR9+/Zp586dunDhgmbMmCGfz2e2WbZsmd566y1VVlaqpqZGp0+f1n333Wce7+zsVG5urjo6OrR37169+uqrKi8v16pVq4L3qQAAQFgLaCXZ7du3+z0vLy9XSkqK6urqdNddd6m1tVWbNm1SRUWF7r77bknS5s2bNWbMGO3bt09Tp07Vu+++q/r6eu3atUtOp1MTJkzQmjVrtGLFCj311FOKi4sL3qcDAABh6brmoLS2tkqSkpOTJUl1dXW6cOGCsrOzzTajR49WRkaGamtrJUm1tbUaN26cnE6n2SYnJ0der1fHjh27nnIAAECE6PW9eLq6urR06VLdcccdGjt2rCTJ4/EoLi5OSUlJfm2dTqc8Ho/Z5tJw0n28+1hP2tvb1d7ebj73er29LRsAAISBXo+gFBUV6eOPP9bWrVuDWU+PSktLlZiYaG7p6el9/p4AACB0ehVQFi9erKqqKr333nsaMWKEud/lcqmjo0MtLS1+7ZuamuRyucw2l1/V0/28u83lSkpK1Nraam6nTp3qTdkAACBMBBRQDMPQ4sWLtW3bNu3evVujRo3yOz5p0iTFxsaqurra3NfQ0KDGxka53W5Jktvt1tGjR9Xc3Gy22blzpxwOhzIzM3t8X5vNJofD4bcBAIDIFdAclKKiIlVUVOjNN9/U0KFDzTkjiYmJGjJkiBITE1VYWKji4mIlJyfL4XDo0Ucfldvt1tSpUyVJM2bMUGZmpubNm6d169bJ4/Fo5cqVKioqks1mC/4nBAAAYSegEZT169ertbVV06ZNU2pqqrm99tprZpvnn39ef//3f6+8vDzdddddcrlcev31183j0dHRqqqqUnR0tNxutx588EHl5+dr9erVwftUANDH8jfuUVRUlKKiopS/cU+oywEiTkAjKIZhfGWbwYMHq6ysTGVlZVdsM3LkSL399tuBvDWAICosPxjqEsJerG2IHtl8INRlABGr15cZA/3h8l+kmx6aEqJKAAD9iZsFAgDCms/nM0+3XXrrFYQ3AgoCxpcBACux2+16ZPMBPbL5gJZU1oe6HAQJp3gQsCWV9ea5d74MAAB9gREUAABgOQQUAABgOQQUAABgOQQUAABgOQQUAAD6GCsPB46reAAA/aKnhRcv3WeFhRj7qh5WHg4cAQVAxGDlYSBycIoHAABYDgEFAABYDgEFAABYDgEFAABYDgEFAABYDgHlGnD9OgAA/YuAcg26r19/ZPMBxdqGBPW1Lw0/Pp8vqK8NAEC4Yh2UELt08R673R7iagAAsAYCCgAAAeir1WZZaNAfAQVAj/iyBKwnHG4XECzMQQEQND6fjzlVAIKCgAKEEasHgCWV9eaE8iWV9aEuB7gqq/97Gug4xYOQ8fl8SkhIkCS1tbUxSfgadAcAqf8nVfPnhUCEw9+XS/89Lamsj6jTI5GAgIKQ4cshvPDnhUDY7Xb+vuC6cIoHAC7D4oxA6DGCAgCXuXR9IgChwQgKAIQQozVAzxhBAYAQYrQG6BkjKAAAwHIYQQEw4EXqSpxAOGMEBQAAWA4BBQAAWA4BBQAAWA4BBQAAWE7AAWXPnj2aM2eO0tLSFBUVpTfeeMPv+EMPPWRe09+9zZw506/N2bNnNXfuXDkcDiUlJamwsFBtbW3X9UEAAOjG+jLhL+CA4vP5dNttt6msrOyKbWbOnKkzZ86Y229+8xu/43PnztWxY8e0c+dOVVVVac+ePVqwYEHg1SPo+EcNIBJ0ry/zyOYDirUNCXU56IWALzOeNWuWZs2addU2NptNLperx2OffPKJtm/froMHD2ry5MmSpJdfflmzZ8/Wz372M6WlpQVaEoLo8kWj8jfu0b8t/I4kad6GGv3q/90VqtIAAANIn8xBef/995WSkqJbbrlFixYt0ueff24eq62tVVJSkhlOJCk7O1uDBg3S/v37e3y99vZ2eb1evw39g/+FAABCIegBZebMmfrVr36l6upq/cu//Itqamo0a9YsdXZ2SpI8Ho9SUlL8fiYmJkbJycnyeDw9vmZpaakSExPNLT09PdhlAwAACwn6SrL333+/+XjcuHEaP368brzxRr3//vuaPn16r16zpKRExcXF5nOv10tIAfTXOWEJCQmSpLa2Ntnt9hBXBADB0eeXGX/jG9/Q8OHDdfz4cUmSy+VSc3OzX5uLFy/q7NmzV5y3YrPZ5HA4/DYA0pLKevMU3JLK+lCXAwBB0+cB5c9//rM+//xzpaamSpLcbrdaWlpUV1dnttm9e7e6urqUlZXV1+UAAIAwEPApnra2NnM0RJJOnjypw4cPKzk5WcnJyXr66aeVl5cnl8ulEydO6PHHH9dNN92knJwcSdKYMWM0c+ZMzZ8/Xxs2bNCFCxe0ePFi3X///VzBA+CacXoLiGwBj6AcOnRIEydO1MSJEyVJxcXFmjhxolatWqXo6GgdOXJE3/ve9/TNb35ThYWFmjRpkn7/+9/LZrOZr7FlyxaNHj1a06dP1+zZs3XnnXfq5z//efA+FYCIZ7fbOb0FRLCAR1CmTZsmwzCueHzHjh1f+RrJycmqqKgI9K0BAMAAwb14AACA5RBQAABhhVtyDAxBXwcFAIC+dPktORCZGEEBAACWQ0ABgszn85nDzz6fb8C9PwAEA6d4gCDrXt21+/Gmh6aE7P1ZGwTBwJozCAVGUAD0GqM1AwO3VEAoMIICoNcuHy0CgGBhBCUMcYkdgEu/ByJp9IrvN3QjoISh7kvsHtl8QLG2IaEuJ+SC9YXGFyPCyaXfA5E0J6Svvt8uPR3Jv+/wwCkehL1grYnA2gpA5Oq+dxPCByMoAADAcggoAADAcjjFAwBBUlh+0Hzc3+vfAJGGERQAAGA5BBSgH7CgGQAEhlM8QD9g+Xl0u3zZeAA9I6AAQD8irALXhlM8AADAcggoAMICK/0CAwuneACEBVb6xUCUv3GP/m3hdyQNvDlLBBQAACzq0mA+0OYscYoHAABYDgEFAABYDgEFQJ9ikToAvcEcFAB96tJ1P5ZU1nOPGgDXhBEUAABCgNHFq2MEJUKwfHZgLu+vgTY7HpGHv9Phh1WFr46AEiH4ix4Yu93OaQdEFE6lIdJwigcAAFgOAQUAAFgOAQUIAe4rAwBXxxwURKTC8oPmYyuei+e+MgBwdYygAAAAywk4oOzZs0dz5sxRWlqaoqKi9MYbb/gdNwxDq1atUmpqqoYMGaLs7Gx9+umnfm3Onj2ruXPnyuFwKCkpSYWFhVwaG2G4vh8AcD0CDig+n0+33XabysrKejy+bt06vfTSS9qwYYP2798vu92unJwcnT9/3mwzd+5cHTt2TDt37lRVVZX27NmjBQsW9P5TwHK6L3l8ZPMBLamsD3U5AIAwE/AclFmzZmnWrFk9HjMMQy+88IJWrlype+65R5L0q1/9Sk6nU2+88Ybuv/9+ffLJJ9q+fbsOHjyoyZMnS5JefvllzZ49Wz/72c+UlpZ2HR8HAABEgqDOQTl58qQ8Ho+ys7PNfYmJicrKylJtba0kqba2VklJSWY4kaTs7GwNGjRI+/fv7/F129vb5fV6/TYAABC5ghpQPB6PJMnpdPrtdzqd5jGPx6OUlBS/4zExMUpOTjbbXK60tFSJiYnmlp6eHsyyAQCAxYTFVTwlJSVqbW01t1OnToW6JAAA0IeCGlBcLpckqampyW9/U1OTeczlcqm5udnv+MWLF3X27FmzzeVsNpscDoffBgAAIldQA8qoUaPkcrlUXV1t7vN6vdq/f7/cbrckye12q6WlRXV1dWab3bt3q6urS1lZWcEsBwAAhKmAr+Jpa2vT8ePHzecnT57U4cOHlZycrIyMDC1dulQ//elPdfPNN2vUqFF64oknlJaWpnvvvVeSNGbMGM2cOVPz58/Xhg0bdOHCBS1evFj3338/V/AAAABJvQgohw4d0t/93d+Zz4uLiyVJBQUFKi8v1+OPPy6fz6cFCxaopaVFd955p7Zv367BgwebP7NlyxYtXrxY06dP16BBg5SXl6eXXnopCB8HQCTw+XxKSEiQ9Nf/FNnt9hBXBKC/BRxQpk2bJsMwrng8KipKq1ev1urVq6/YJjk5WRUVFYG+NYABwm63m/cqWlJZb8n7KQHoW2FxFQ8AAOhbVrtFCXczBgAA5i1Kuh+HeuSSERQAAGA5BBQAAGA5BBQAAGA5BBQgAPkb95iTyPI37gl1OQAQsZgkCwQg1jbEnEQGAOg7jKAAAADLYQSllwrLD5qPQ30p1kBD3wNA5GMEpR9ZbREcAACsioDSj7oXwXlk8wEtqawPdTkDCuEQAMILp3gwIFhthUQAwNUxggIAACyHgAJYFGuuABjIOMUDWBRrrgAYyBhBAQAAlkNAAQAAlsMpniC5dPEwiQXEBhIWjgNgJZHy+4gRFAAAYDkEFAAAYDkEFAAAYDkEFOAKWB4fAEKHgAJcgd1u595JuC4stgf0HlfxAEAfYbE9oPcYQQEAAJZDQOlDlw7vMocBAIBrxymePnTp8K7dbg9xNQAAhA8CShhgpVIAwEBDQAEA4DpEytLyVsMcFIth7Q0AABhBsZwllfXmvJUllfUkcQDAgMQICvrFtYwMMXoEAOjGCAr6xbWMDHWv3Hq1NgCAgYERFAD96tKRMpZ/B3AljKAA6FeXjpQBwJUEfQTlqaeeMv931L2NHj3aPH7+/HkVFRVp2LBhSkhIUF5enpqamoJdBgDgGnBDQ1hVn4yg3Hrrrdq1a9f/vUnM/73NsmXL9B//8R+qrKxUYmKiFi9erPvuu0//+Z//2RelAACughsawqr6JKDExMTI5XJ9aX9ra6s2bdqkiooK3X333ZKkzZs3a8yYMdq3b5+mTp3aF+UAAIAw0ycB5dNPP1VaWpoGDx4st9ut0tJSZWRkqK6uThcuXFB2drbZdvTo0crIyFBtbe0VA0p7e7va29vN516vty/KBoCIwm0yEM6CPgclKytL5eXl2r59u9avX6+TJ0/qb//2b3Xu3Dl5PB7FxcUpKSnJ72ecTqc8Hs8VX7O0tFSJiYnmlp6eHuyyAQCIWOG4zlTQR1BmzZplPh4/fryysrI0cuRI/fa3v9WQIUN69ZolJSUqLi42n3u9XkIKAADX6PK1qMJBn6+DkpSUpG9+85s6fvy4XC6XOjo61NLS4temqampxzkr3Ww2mxwOh98GAAAiV58HlLa2Np04cUKpqamaNGmSYmNjVV1dbR5vaGhQY2Oj3G53X5cCAADCRNBP8fzzP/+z5syZo5EjR+r06dN68sknFR0drQceeECJiYkqLCxUcXGxkpOT5XA49Oijj8rtdnMFDwAAMAU9oPz5z3/WAw88oM8//1xf//rXdeedd2rfvn36+te/Lkl6/vnnNWjQIOXl5am9vV05OTl65ZVXgl0GAAAIY0EPKFu3br3q8cGDB6usrExlZWXBfmsAABAhuFkgAACwHAIKAACwHAIKAACwHAIKAACwHAIKAACwHAIKAACwHAIKAACwHAIKAACwHAIKAACwHAIKACAg+Rv3KCoqSlFRUcrfuCfU5SBCBX2pewBAZIu1DdEjmw+EugxEOEZQAACA5RBQAACA5RBQAACA5RBQAACA5RBQAACA5RBQAACA5RBQAACA5RBQAACA5RBQAACA5RBQAACA5RBQAACA5RBQAACA5RBQAACA5RBQAACA5RBQAACA5RBQAACA5RBQAACA5RBQAACA5RBQAACA5RBQAACA5RBQAACA5RBQAACA5RBQAACA5YQ0oJSVlemGG27Q4MGDlZWVpQMHDoSyHAAAYBEhCyivvfaaiouL9eSTT+rDDz/UbbfdppycHDU3N4eqJAAAYBEhCyjPPfec5s+fr4cffliZmZnasGGD4uPj9ctf/jJUJQEAAIuICcWbdnR0qK6uTiUlJea+QYMGKTs7W7W1tV9q397ervb2dvN5a2urJMnr9fZNfX9pMx97vV6/5z3ti9Q2PenLNlbvj0ht0xP+nAdmm57w5xx5bXpypZ8Ltu7XNAzjqxsbIfDZZ58Zkoy9e/f67V++fLlx++23f6n9k08+aUhiY2NjY2Nji4Dt1KlTX5kVQjKCEqiSkhIVFxebz7u6unT27FkNGzZMUVFR1/36Xq9X6enpOnXqlBwOx3W/HnpGP/cf+rp/0M/9g37uP33d14Zh6Ny5c0pLS/vKtiEJKMOHD1d0dLSampr89jc1Ncnlcn2pvc1mk81m89uXlJQU9LocDgd/+fsB/dx/6Ov+QT/3D/q5//RlXycmJl5Tu5BMko2Li9OkSZNUXV1t7uvq6lJ1dbXcbncoSgIAABYSslM8xcXFKigo0OTJk3X77bfrhRdekM/n08MPPxyqkgAAgEWELKB8//vf1//8z/9o1apV8ng8mjBhgrZv3y6n09nvtdhsNj355JNfOo2E4KKf+w993T/o5/5BP/cfK/V1lGFcy7U+AAAA/Yd78QAAAMshoAAAAMshoAAAAMshoAAAAMsZ8AGlrKxMN9xwgwYPHqysrCwdOHAg1CWFvdLSUk2ZMkVDhw5VSkqK7r33XjU0NPi1OX/+vIqKijRs2DAlJCQoLy/vSwv3ITBr165VVFSUli5dau6jn4Pjs88+04MPPqhhw4ZpyJAhGjdunA4dOmQeNwxDq1atUmpqqoYMGaLs7Gx9+umnIaw4PHV2duqJJ57QqFGjNGTIEN14441as2aN331b6OvA7dmzR3PmzFFaWpqioqL0xhtv+B2/lj49e/as5s6dK4fDoaSkJBUWFqqt7er397lu139nnfC1detWIy4uzvjlL39pHDt2zJg/f76RlJRkNDU1hbq0sJaTk2Ns3rzZ+Pjjj43Dhw8bs2fPNjIyMoy2tjazzcKFC4309HSjurraOHTokDF16lTj29/+dgirDm8HDhwwbrjhBmP8+PHGY489Zu6nn6/f2bNnjZEjRxoPPfSQsX//fuNPf/qTsWPHDuP48eNmm7Vr1xqJiYnGG2+8YfzhD38wvve97xmjRo0y/vKXv4Sw8vDzzDPPGMOGDTOqqqqMkydPGpWVlUZCQoLx4osvmm3o68C9/fbbxk9+8hPj9ddfNyQZ27Zt8zt+LX06c+ZM47bbbjP27dtn/P73vzduuukm44EHHujTugd0QLn99tuNoqIi83lnZ6eRlpZmlJaWhrCqyNPc3GxIMmpqagzDMIyWlhYjNjbWqKysNNt88sknhiSjtrY2VGWGrXPnzhk333yzsXPnTuM73/mOGVDo5+BYsWKFceedd17xeFdXl+FyuYx//dd/Nfe1tLQYNpvN+M1vftMfJUaM3Nxc45FHHvHbd9999xlz5841DIO+DobLA8q19Gl9fb0hyTh48KDZ5p133jGioqKMzz77rM9qHbCneDo6OlRXV6fs7Gxz36BBg5Sdna3a2toQVhZ5WltbJUnJycmSpLq6Ol24cMGv70ePHq2MjAz6vheKioqUm5vr158S/Rws//7v/67JkyfrH//xH5WSkqKJEyfqF7/4hXn85MmT8ng8fv2cmJiorKws+jlA3/72t1VdXa0//vGPkqQ//OEP+uCDDzRr1ixJ9HVfuJY+ra2tVVJSkiZPnmy2yc7O1qBBg7R///4+qy0s7mbcF/73f/9XnZ2dX1q51ul06r/+679CVFXk6erq0tKlS3XHHXdo7NixkiSPx6O4uLgv3fDR6XTK4/GEoMrwtXXrVn344Yc6ePDgl47Rz8Hxpz/9SevXr1dxcbF+/OMf6+DBg1qyZIni4uJUUFBg9mVP3yX0c2B+9KMfyev1avTo0YqOjlZnZ6eeeeYZzZ07V5Lo6z5wLX3q8XiUkpLidzwmJkbJycl92u8DNqCgfxQVFenjjz/WBx98EOpSIs6pU6f02GOPaefOnRo8eHCoy4lYXV1dmjx5sp599llJ0sSJE/Xxxx9rw4YNKigoCHF1keW3v/2ttmzZooqKCt166606fPiwli5dqrS0NPp6ABqwp3iGDx+u6OjoL13R0NTUJJfLFaKqIsvixYtVVVWl9957TyNGjDD3u1wudXR0qKWlxa89fR+Yuro6NTc361vf+pZiYmIUExOjmpoavfTSS4qJiZHT6aSfgyA1NVWZmZl++8aMGaPGxkZJMvuS75Lrt3z5cv3oRz/S/fffr3HjxmnevHlatmyZSktLJdHXfeFa+tTlcqm5udnv+MWLF3X27Nk+7fcBG1Di4uI0adIkVVdXm/u6urpUXV0tt9sdwsrCn2EYWrx4sbZt26bdu3dr1KhRfscnTZqk2NhYv75vaGhQY2MjfR+A6dOn6+jRozp8+LC5TZ48WXPnzjUf08/X74477vjSZfJ//OMfNXLkSEnSqFGj5HK5/PrZ6/Vq//799HOAvvjiCw0a5P9rKTo6Wl1dXZLo675wLX3qdrvV0tKiuro6s83u3bvV1dWlrKysviuuz6bfhoGtW7caNpvNKC8vN+rr640FCxYYSUlJhsfjCXVpYW3RokVGYmKi8f777xtnzpwxty+++MJss3DhQiMjI8PYvXu3cejQIcPtdhtutzuEVUeGS6/iMQz6ORgOHDhgxMTEGM8884zx6aefGlu2bDHi4+ONX//612abtWvXGklJScabb75pHDlyxLjnnnu49LUXCgoKjL/5m78xLzN+/fXXjeHDhxuPP/642Ya+Dty5c+eMjz76yPjoo48MScZzzz1nfPTRR8Z///d/G4ZxbX06c+ZMY+LEicb+/fuNDz74wLj55pu5zLivvfzyy0ZGRoYRFxdn3H777ca+fftCXVLYk9TjtnnzZrPNX/7yF+Of/umfjK997WtGfHy88Q//8A/GmTNnQld0hLg8oNDPwfHWW28ZY8eONWw2mzF69Gjj5z//ud/xrq4u44knnjCcTqdhs9mM6dOnGw0NDSGqNnx5vV7jscceMzIyMozBgwcb3/jGN4yf/OQnRnt7u9mGvg7ce++91+N3ckFBgWEY19ann3/+ufHAAw8YCQkJhsPhMB5++GHj3LlzfVp3lGFcskQfAACABQzYOSgAAMC6CCgAAMByCCgAAMByCCgAAMByCCgAAMByCCgAAMByCCgAAMByCCgAAMByCCgAAMByCCgAAMByCCgAAMByCCgAAMBy/j/WsGFc4vXutAAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "means2 = []\n",
        "stds2 = []\n",
        "\n",
        "for i in range(perc_opt_act2.shape[1]):\n",
        "    mean_t2 = []\n",
        "    std_t2 = []\n",
        "    for j in  range(perc_opt_act2.shape[0]):\n",
        "        avg_perc2 = np.average(perc_opt_act2[j,i,:,:],axis = 0)\n",
        "        std_perc2 = np.std(perc_opt_act2[j,i,:,:],axis = 0)\n",
        "        a = list(np.asarray(avg_perc2 > 0.7).nonzero()[0])\n",
        "        a.append(-1)\n",
        "        mean_t2.append(a[0])\n",
        "        std_t2.append(std_perc2[a[0]])\n",
        "    \n",
        "    means2.append(mean_t2)\n",
        "    stds2.append(std_t2)\n",
        "    plt.bar(list(range(1,101)), mean_t2, yerr = std_t2, alpha = 0.7)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "means2 = []\n",
        "stds2 = []\n",
        "\n",
        "for i in range(perc_opt_act2.shape[1]):\n",
        "    mean_t2 = []\n",
        "    std_t2 = []\n",
        "    for j in  range(perc_opt_act2.shape[0]):\n",
        "        avg_perc2 = np.average(perc_opt_act2[j,i,:,:],axis = 0)\n",
        "        std_perc2 = np.std(perc_opt_act2[j,i,:,:],axis = 0)\n",
        "        a = list(np.asarray(avg_perc2 > 0.7).nonzero()[0])\n",
        "        a.append(-1)\n",
        "        mean_t2.append(a[0])\n",
        "        std_t2.append(std_perc2[a[0]])\n",
        "    \n",
        "    means2.append(mean_t2)\n",
        "    stds2.append(std_t2)\n",
        "    plt.bar(list(range(1,101)), mean_t2, yerr = std_t2, alpha = 0.7)\n",
        "    # plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('results/budget_bernouli_means.pkl', 'wb') as f:\n",
        "    pickle.dump(means2, f)\n",
        "\n",
        "with open('results/budget_bernouli_stds.pkl', 'wb') as f:\n",
        "    pickle.dump(stds2, f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('results/budget_bernouli_means.pkl', 'rb') as f:\n",
        "    means2 = pickle.load(f)\n",
        "\n",
        "with open('results/budget_bernouli_means.pkl', 'rb') as f:\n",
        "    stds2 = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "73ZyrJoSEr0j",
        "DDAUQ9OOE00W",
        "11fHtdR3E5X_",
        "7vTZafAEE-8H",
        "syUMOjD4LRpi",
        "zTOmpSzeEpZG",
        "BX5FnIHPghU-",
        "08iqgbLWGnli",
        "4XEXTLpjLleb",
        "TweQfzExrl2h",
        "6BJbW-zkPpy4",
        "WT-G_muSJW2U",
        "dSXb24Vq6yif",
        "H6vbj3WyfdkB",
        "E-hbh1D9g8hs",
        "LONuJmsyLCGc",
        "mUI9t3XXVJU1",
        "5XkuDlazF9Km",
        "ta_gpxwmavYo",
        "_Tk0kSAJaVq0",
        "FIZ9id7QbjuY",
        "W8lAjfkQG4gA",
        "DHlla2SIaVq2",
        "Bux9quy7bjub",
        "dyD7ztIec--M",
        "JpG-cQECc--V",
        "yOWqCVbnc--Q",
        "DHU7qJwUc--b",
        "qK7rSe1Lc--k"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
